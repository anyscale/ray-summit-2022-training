{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Tour of Ray Core: Remote Stateful Classes\n",
    "\n",
    "© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "### Learning objectives\n",
    "In this this tutorial, we'll discuss Ray Actors and learn about:\n",
    " * How Ray Actors work\n",
    " * How to write a stateful Ray Actor\n",
    " * How Ray Actors can be writen as a statful distributed service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*Remote Classes*](https://docs.ray.io/en/latest/walkthrough.html#remote-classes-actors)\n",
    "involve using a `@ray.remote` decorator on a class. \n",
    "\n",
    "This implements an [*actor*](https://patterns.eecs.berkeley.edu/?page_id=258) pattern, with properties: *stateful*, *message-passing semantics*\n",
    "\n",
    "Actors are extremely powerful. They allow you to take a Python class and instantiate it as a stateful microservice that can be queried from other actors and tasks and even other Python applications.\n",
    "\n",
    "When you instantiate a remote Actor, a separate worker process is created as a worker process and becomes an Actor process on the worker node, for the purpose of running methods called on the actor. Other Ray tasks and actors can invoke its methods on that process, mutating its internal state. Actors can also be terminated manually if needed. The examples code below show all these cases.\n",
    "\n",
    "<img src=\"images/ray_worker_actor_1.png\" height=\"40%\" width=\"70%\">\n",
    "<img src=\"images/ray_worker_actor_2.png\" height=\"40%\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start Ray…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "import ray\n",
    "import random\n",
    "from random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.12', ray_version='1.12.0', ray_commit='f18fc31c7562990955556899090f8e8656b48d2d', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-05-17_14-13-36_212995_43088/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-05-17_14-13-36_212995_43088/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-05-17_14-13-36_212995_43088', 'metrics_export_port': 62091, 'gcs_address': '127.0.0.1:61279', 'address': '127.0.0.1:61279', 'node_id': '47d9a2d97ac61d1f3ec9b8be624073b689ca0ec1443c183e8f9d20c9'})\n"
     ]
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "context = ray.init(logging_level=logging.ERROR)\n",
    "pprint(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard url: http://127.0.0.1:8265\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dashboard url: http://{context.address_info['webui_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remote Class as a Stateful Actor Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll define a class and use the decorator: `@ray.remote`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Python class and convert that to a remote Actor class actor service as a Parameter Server. This is a common example in machine learning where you have a central Parameter server updating gradients from other worker processes computing individual gradients. \n",
    "\n",
    "<img src=\"https://terrytangyuan.github.io/img/inblog/mpi-operator-1.png\" width=\"60%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class ParameterSever:\n",
    "    def __init__(self):\n",
    "        # Initialized our gradients to zero\n",
    "        self.params = np.zeros(10)\n",
    "\n",
    "    def get_params(self):\n",
    "        # Return current gradients\n",
    "        return self.params\n",
    "\n",
    "    def update_params(self, grad):\n",
    "        # Update the gradients \n",
    "        self.params -= grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define worker or task as a function for a remote Worker process. This could be a machine learning objective function that computes gradients and sends them to the parameter server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def worker(ps):\n",
    "    # Iterate over some epoch\n",
    "    for i in range(25):\n",
    "        time.sleep(1.5)  # this could be your loss function computing gradients\n",
    "        grad = np.ones(10)\n",
    "        # update the gradients in the parameter server\n",
    "        ps.update_params.remote(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start our Parameter Server actor. This will be scheduled as a process on a remote Ray Worker. You invoke its `ActorClass.remote(...)` to instantiate an Actor instance of that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(ParameterSever, f0f29fd04d0e89d3b7cc696e01000000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_server = ParameterSever.remote()\n",
    "param_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the initial values of the parameter server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial params: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial params: {ray.get(param_server.get_params.remote())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Workers Nodes Computing Gradients\n",
    "Let's create three separate workers as our machine learning tasks that compute gradients.\n",
    "These will be scheduled as tasks on a Ray cluster.\n",
    "\n",
    "You can use list comprehension. Quite Pythonic!\n",
    "\n",
    "If we need more workers to scale, we can always bump them up.\n",
    "\n",
    "**Note**: That we are sending the `parameter_server` as an argument to the remote\n",
    "worker task. Ray will resolve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectRef(c2668a65bda616c1ffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(32d950ec0ccf9d2affffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(e0dc174c83599034ffffffffffffffffffffffff0100000001000000)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[worker.remote(param_server) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's iterate over a loop and query the Parameter Server \n",
    "as the workers are running independently and updating the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated params: [-9. -9. -9. -9. -9. -9. -9. -9. -9. -9.]\n",
      "Updated params: [-12. -12. -12. -12. -12. -12. -12. -12. -12. -12.]\n",
      "Updated params: [-12. -12. -12. -12. -12. -12. -12. -12. -12. -12.]\n",
      "Updated params: [-15. -15. -15. -15. -15. -15. -15. -15. -15. -15.]\n",
      "Updated params: [-18. -18. -18. -18. -18. -18. -18. -18. -18. -18.]\n",
      "Updated params: [-18. -18. -18. -18. -18. -18. -18. -18. -18. -18.]\n",
      "Updated params: [-21. -21. -21. -21. -21. -21. -21. -21. -21. -21.]\n",
      "Updated params: [-24. -24. -24. -24. -24. -24. -24. -24. -24. -24.]\n",
      "Updated params: [-24. -24. -24. -24. -24. -24. -24. -24. -24. -24.]\n",
      "Updated params: [-27. -27. -27. -27. -27. -27. -27. -27. -27. -27.]\n",
      "Updated params: [-30. -30. -30. -30. -30. -30. -30. -30. -30. -30.]\n",
      "Updated params: [-30. -30. -30. -30. -30. -30. -30. -30. -30. -30.]\n",
      "Updated params: [-33. -33. -33. -33. -33. -33. -33. -33. -33. -33.]\n",
      "Updated params: [-36. -36. -36. -36. -36. -36. -36. -36. -36. -36.]\n",
      "Updated params: [-36. -36. -36. -36. -36. -36. -36. -36. -36. -36.]\n",
      "Updated params: [-39. -39. -39. -39. -39. -39. -39. -39. -39. -39.]\n",
      "Updated params: [-42. -42. -42. -42. -42. -42. -42. -42. -42. -42.]\n",
      "Updated params: [-42. -42. -42. -42. -42. -42. -42. -42. -42. -42.]\n",
      "Updated params: [-45. -45. -45. -45. -45. -45. -45. -45. -45. -45.]\n",
      "Updated params: [-48. -48. -48. -48. -48. -48. -48. -48. -48. -48.]\n"
     ]
    }
   ],
   "source": [
    "for _i in range(20):\n",
    "    print(f\"Updated params: {ray.get(param_server.get_params.remote())}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Ray Dashboard\n",
    "\n",
    "You should see Actors running as process on the workers nodes\n",
    " * Parameter Server\n",
    " \n",
    "Also, click on the `Logical View` to view more metrics and data on individual Ray Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, shutdown Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Add a remote class, that keeps states by keeping track in a Actor class instance (may be only in memory)\n",
    "2. Implement methods that alters the state\n",
    "3. Instantiate it and call its methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Writing your First Distributed Python Application with Ray](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray)\n",
    " * [Using and Programming with Actors](https://docs.ray.io/en/latest/actors.html)\n",
    " * [Advanced Patterns and Anti-Patterns in Ray](https://docs.ray.io/en/latest/ray-design-patterns/index.htmlhttps://docs.ray.io/en/latest/ray-design-patterns/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
