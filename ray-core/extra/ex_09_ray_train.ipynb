{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef3ff2e-b5ec-466f-86d8-f08eb2f1402d",
   "metadata": {},
   "source": [
    "# Ray Train - A Gentle introuduction to Ray Train: \n",
    "A library for distributed training for deep learning\n",
    "\n",
    "Â© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "ðŸ“– [Back to Table of Contents](../ex_00_tutorial_overview.ipynb)<br>\n",
    "\n",
    "### Learning Objective:\n",
    "In this introductory tutorial, you will:\n",
    " * understand the Ray Train library components and architecture\n",
    " * how to use its API to build distributed trainer\n",
    " * walk through a FashionMNIST PyTorch example \n",
    "\n",
    "### Introduction to Ray Train\n",
    "\n",
    "Ray Train is a library that aims to simplify distributed deep learning. As a library, Ray Train is built to abstract away the coordination/configuration setup of distributed deep learning frameworks such as [Pytorch Distributed](https://pytorch.org/tutorials/beginner/dist_overview.html) and [Tensorflow Distributed](https://www.tensorflow.org/guide/distributed_training), allowing users to only focus on implementing training logic for their respective framework. For example: \n",
    " * For Pytorch, Ray Train automatically handles the construction of the distributed process group.\n",
    " * For Tensorflow, Ray Train automatically handles the coordination of the `TF_CONFIG`. The current implementation assumes that the user will use a _MultiWorkerMirroredStrategy_, but this will change in the near future.\n",
    " * For Horovod, Ray Train automatically handles the construction of the Horovod runtime and [Rendezvous server](https://horovod.readthedocs.io/en/stable/_modules/horovod/ray/runner.html).\n",
    "\n",
    "Built for data scientists/ML practitioners, Ray Train has support for standard ML tools and features that practitioners love. For example:\n",
    " * Callbacks for early stopping, reducing costs and time for training\n",
    " * Checkpointing at regular intervals, allowing to restart for fault-tolerence\n",
    " * Integration with Tensorboard, Weights/Biases, and MLflow, providing extensibilty for experimentation and observation of runs\n",
    " * Jupyter notebooks, giving developers familiar development tools for iteration and experimentation\n",
    "\n",
    "More importantly, Ray Train integrates with the Ray Ecosystem. Distributed deep learning often comes with a lot of complexity, so you can:\n",
    " * Use [Ray Datasets](https://docs.ray.io/en/latest/data/dataset.html#datasets) with Ray Train to inject, handle or train on large amounts of data\n",
    " * Use [Ray Tune](https://docs.ray.io/en/latest/tune/index.html#tune-main) with Ray Train to leverage cutting edge hyperparameter techniques and distribute both your training and tuning\n",
    "\n",
    "> **NOTE**: Ray SGD is renamed to Ray Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd06b4-535a-4a0e-ac45-8ca62f9a971e",
   "metadata": {},
   "source": [
    "### Ray Train Architecture and concepts\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/train-arch.svg\" width=\"70%\" height=\"3%\"> \n",
    "\n",
    "**Trainer**: The Trainer is the main class that is exposed in the [Ray Train API](https://docs.ray.io/en/latest/train/api.html) that users will interact with. A user will pass in a function which defines the training logic. In our case, the trainin\n",
    "function is `train_func_distributed` with `configs` as its argument. The Trainer will create an Executor to run the distributed training. It will also will handle callbacks based on the results from the `BackendExecutor`. Read the Trainer [source here](https://github.com/ray-project/ray/blob/f1acabe9cf37d5d123017fb3f158c37fb36499a5/python/ray/train/trainer.py#L78).\n",
    "\n",
    "**BackendExecutor**: The executor is an interface that handles execution of distributed training. It creates an actor group and initializes in conjunction with a specific backend. Worker resources, number of workers, and placement strategy are passed to the `Worker Group.` Read the BackendExecutor [source here](https://github.com/ray-project/ray/blob/f1acabe9cf37d5d123017fb3f158c37fb36499a5/python/ray/train/backend.py#L102).\n",
    "\n",
    "**Backend**: A backend is used in conjunction with the `Executor` to initialize and manage framework-specific communication protocols. Each communication library (Torch, Horovod, TensorFlow, etc.) will have a separate backend and will take a specific configuration value. In the diagram, they are labelled as `XBackend`, `XConfig`, `YBackend`, and `YConfig` respectively. Read the Backend [source here](https://github.com/ray-project/ray/blob/f1acabe9cf37d5d123017fb3f158c37fb36499a5/python/ray/train/trainer.py#L64).\n",
    "\n",
    "**WorkerGroup**:The `WorkerGroup` is a generic utility class for managing a group of Ray Actors, regardless of the backend. Read WorkGroup [source here](https://github.com/ray-project/ray/blob/f1acabe9cf37d5d123017fb3f158c37fb36499a5/python/ray/train/worker_group.py#L84).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3eda8-7185-48d4-9ff1-679621b987fd",
   "metadata": {},
   "source": [
    "## PyTorch Fashion MNIST for Distributed Training\n",
    "\n",
    "<img src=\"../images/fashion-mnist-sprite.jpeg\" width=\"70%\" height=\"35%\"> \n",
    "\n",
    "We will use Ray Train to distribute our training using couple of models and evaluating which of the two provides us\n",
    "the best accuracy and a minimal loss. \n",
    "\n",
    "As excercise, you can try to further investigate how you improve the modelâ€”via regularization techniques, using CNN layers, trying different loss functions.\n",
    "\n",
    "The steps we will follow can be applied to any of your models too.\n",
    "\n",
    "So let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755b099-304f-49dd-a935-303133d42126",
   "metadata": {},
   "source": [
    "First, do the necessary imports, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16002ec-9ec0-4c26-bee0-c839601aea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray.train.trainer import Trainer\n",
    "from ray.train.callbacks import JsonLoggerCallback, TBXLoggerCallback\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9e3ab-d950-42a0-adf2-cfa57eaec74d",
   "metadata": {},
   "source": [
    "### Step 1: Download Train and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a05d4628-08c2-4d4f-89aa-939eb819a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"~/data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"~/data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd077dca-a562-4625-af4e-f0c5e068c712",
   "metadata": {},
   "source": [
    "## Step 2: Define a Neural Network Models. \n",
    "\n",
    "This is a quite simple NN model\n",
    "\n",
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f805792-c35a-4fef-b8bc-53fbea7eecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-1\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 10), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6ad67-8968-4c6d-a106-708e704d67b4",
   "metadata": {},
   "source": [
    "Define a deeper NN model archiecture with dropouts\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*2SHOuTUK51_Up3D9JMAplA.png\" width=\"70%\" height=\"50%\">\n",
    "\n",
    "[source](https://medium.com/@aaysbt/fashion-mnist-data-training-using-pytorch-7f6ad71e96f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b3be6-3008-411b-8554-f710c98ee688",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "653205a7-d6e3-4e5f-9627-42b69950529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-2\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 120)\n",
    "    self.fc2 = nn.Linear(120, 120)\n",
    "    self.fc3 = nn.Linear(120,10)\n",
    "    self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = self.dropout(F.relu(self.fc1(x)))\n",
    "    x = self.dropout(F.relu(self.fc2(x)))\n",
    "    x = F.log_softmax(self.fc3(x), dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf7695d5-7ce3-44f3-a602-b9e04a471dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy function\n",
    "def accuracy_fn(y_pred, y_true):\n",
    "    n_correct = torch.eq(y_pred, y_true).sum().item()\n",
    "    acc = (n_correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6bc36-8344-4792-b9ee-c89c9f741016",
   "metadata": {},
   "source": [
    "### Step 3: Define per epoch training and validation functinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf218b87-a60c-4ee4-8952-7cf3a0abb5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "314c237f-f16e-47f3-b2d1-17f9c6eaa075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, acc =  0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            predictions = pred.max(dim=1)[1]\n",
    "            acc += accuracy_fn(predictions, y)\n",
    "    test_loss /= num_batches\n",
    "    acc /= num_batches\n",
    "    correct /= size\n",
    "    if epoch > 0 and epoch % 50 == 0:\n",
    "        print(f\"Epoc: {epoch}, Avg validation loss: {test_loss:.2f}, Avg validation accuracy: {acc:.2f}%\") \n",
    "        print(\"--\" * 40)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671c44a-7def-44b8-a468-704694c61d91",
   "metadata": {},
   "source": [
    "### Step 4: Define Ray Train Training function\n",
    "This function will be passed to `train.run(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d2ccc74-555f-40c7-a54a-75506c7cbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config: Dict):\n",
    "    batch_size = config.get(\"batch_size\", 64) \n",
    "    lr = config.get('lr', 1e-3)\n",
    "    epochs = config.get(\"epochs\", 20)\n",
    "    momentum = config.get(\"momentum\", 0.9)\n",
    "    model_type = config.get('model_type', 0)\n",
    "    loss_fn = config.get(\"loss_fn\", nn.NLLLoss())\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    # Prepare to use Ray integrated wrappers around PyTorch's Dataloaders\n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    # Create model.\n",
    "    model = Classifier() if model_type else NeuralNetwork()\n",
    "    # Prepare to use Ray integrated wrappers around PyTorch's model\n",
    "    model = train.torch.prepare_model(model)\n",
    "    \n",
    "    # Get or objective loss function\n",
    "    loss_fn = config.get(\"loss_fn\", nn.NLLLoss())\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    loss_results = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer, e)\n",
    "        loss = validate_epoch(test_dataloader, model, loss_fn, e)\n",
    "        train.report(loss=loss)\n",
    "        loss_results.append(loss)\n",
    "\n",
    "    return loss_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242704c-0ec7-43e6-a7b8-27fa37dedb53",
   "metadata": {},
   "source": [
    "### Step 5: Wrap our Trainer around a main driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9280b0c5-c754-4416-83ec-1f02c3028483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fashion_mnist(num_workers=12, use_gpu=False):\n",
    "    trainer = Trainer(\n",
    "        backend=\"torch\", num_workers=num_workers, use_gpu=use_gpu)\n",
    "    trainer.start()\n",
    "    result = trainer.run(\n",
    "        train_func=train_func,\n",
    "        config={\n",
    "            \"lr\": 1e-3,\n",
    "            \"batch_size\": 128,\n",
    "            \"epochs\": 150,\n",
    "            \"momentum\": 0.9,\n",
    "            \"model_type\": 0,                     # Use 0 for Model-1 and 1 to Model-2 (Classifier())\n",
    "            \"loss_fn\": nn.CrossEntropyLoss()     # change to nn.nn.NLLLoss() \n",
    "        },\n",
    "        callbacks=[JsonLoggerCallback(), TBXLoggerCallback()])\n",
    "    trainer.shutdown() \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6ab92-10c2-4594-84a9-f475ba634a0a",
   "metadata": {},
   "source": [
    "### Step 6: Define some parallelism parameters \n",
    "And a URL to connect to a Ray Cluster if running on Anysacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc5b6b09-54f8-4485-b5e0-8a3051e5d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_workers = 8\n",
    "use_gpu = False                              # change to True if using a Ray cluster with GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a49aa6-21db-4273-bcfa-bc59b4b9d0dc",
   "metadata": {},
   "source": [
    "### Step 6: Connect to Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465829b7-f72c-4532-80f5-5a69f470fa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8274\" target=\"_blank\">http://127.0.0.1:8274</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8274', python_version='3.8.13', ray_version='3.0.0.dev0', ray_commit='{{RAY_COMMIT_SHA}}', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-07-29_10-28-42_014732_3086/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-29_10-28-42_014732_3086/sockets/raylet', 'webui_url': '127.0.0.1:8274', 'session_dir': '/tmp/ray/session_2022-07-29_10-28-42_014732_3086', 'metrics_export_port': 62071, 'gcs_address': '127.0.0.1:60684', 'address': '127.0.0.1:60684', 'dashboard_agent_listen_port': 52365, 'node_id': '17e3d09b703eb04a7317be44d156f1ac220902b51f8fd160f6d4c93c'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93caaba-d57b-4a4a-8a06-49dd01474aaf",
   "metadata": {},
   "source": [
    "### Step 7: Run the main Trainer driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d41e4c6c-332b-4c68-8de4-e45c60647e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m 2022-05-27 18:08:34,136\tINFO torch.py:334 -- Setting up process group for: env:// [rank=2, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m 2022-05-27 18:08:34,131\tINFO torch.py:334 -- Setting up process group for: env:// [rank=4, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m 2022-05-27 18:08:34,143\tINFO torch.py:334 -- Setting up process group for: env:// [rank=1, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m 2022-05-27 18:08:34,148\tINFO torch.py:334 -- Setting up process group for: env:// [rank=5, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m 2022-05-27 18:08:34,145\tINFO torch.py:334 -- Setting up process group for: env:// [rank=7, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m 2022-05-27 18:08:34,120\tINFO torch.py:334 -- Setting up process group for: env:// [rank=3, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m 2022-05-27 18:08:34,141\tINFO torch.py:334 -- Setting up process group for: env:// [rank=6, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m 2022-05-27 18:08:34,143\tINFO torch.py:334 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m [W ProcessGroupGloo.cpp:715] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m 2022-05-27 18:08:36,505\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m 2022-05-27 18:08:36,507\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m 2022-05-27 18:08:36,507\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m 2022-05-27 18:08:36,507\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m 2022-05-27 18:08:36,507\tINFO torch.py:126 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m 2022-05-27 18:08:36,505\tINFO torch.py:92 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m 2022-05-27 18:08:36,506\tINFO torch.py:126 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m Epoc: 50, Avg validation loss: 0.59, Avg validation accuracy: 79.10%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m Epoc: 50, Avg validation loss: 0.59, Avg validation accuracy: 78.95%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m Epoc: 50, Avg validation loss: 0.58, Avg validation accuracy: 79.97%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m Epoc: 50, Avg validation loss: 0.57, Avg validation accuracy: 80.59%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m Epoc: 50, Avg validation loss: 0.55, Avg validation accuracy: 81.09%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m Epoc: 50, Avg validation loss: 0.58, Avg validation accuracy: 79.83%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m Epoc: 50, Avg validation loss: 0.53, Avg validation accuracy: 81.04%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m Epoc: 50, Avg validation loss: 0.51, Avg validation accuracy: 82.84%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m Epoc: 100, Avg validation loss: 0.50, Avg validation accuracy: 81.36%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m Epoc: 100, Avg validation loss: 0.51, Avg validation accuracy: 81.10%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26055)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m Epoc: 100, Avg validation loss: 0.51, Avg validation accuracy: 81.59%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26051)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m Epoc: 100, Avg validation loss: 0.51, Avg validation accuracy: 81.25%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m Epoc: 100, Avg validation loss: 0.50, Avg validation accuracy: 82.56%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26057)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m Epoc: 100, Avg validation loss: 0.44, Avg validation accuracy: 84.87%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m Epoc: 100, Avg validation loss: 0.47, Avg validation accuracy: 84.41%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m --------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m Epoc: 100, Avg validation loss: 0.46, Avg validation accuracy: 83.05%\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26050)\u001b[0m --------------------------------------------------------------------------------\n",
      "CPU times: user 1.87 s, sys: 800 ms, total: 2.67 s\n",
      "Wall time: 4min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26052)\u001b[0m E0527 18:12:43.200063000 123145542377472 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26054)\u001b[0m E0527 18:12:43.200376000 123145394028544 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26053)\u001b[0m E0527 18:12:43.200245000 123145448992768 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(BaseWorkerMixin pid=26056)\u001b[0m E0527 18:12:43.200585000 123145501032448 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = train_fashion_mnist(num_workers=number_of_workers, use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c603e8-6ecb-4e81-8204-7098f48d9627",
   "metadata": {},
   "source": [
    "### Step 8: Observe metrics in Tensorboard \n",
    "\n",
    "Subsitute your path `train_path` printed in the cell below\n",
    "!tensorboard --logdir <train_path/ray_results/<train_func_path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61c5874c-7ea2-455b-bd03-39c5a5c119af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mtrain_2022-05-27_18-08-29\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ~/ray_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf734e-4e4d-48a4-b20f-b06871effeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir ~/ray_results/train_2022-05-27_18-08-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b66eae-1404-4a36-9bae-0c96c5567627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89653c-7e00-48ea-b6b1-6e50d9ab4a38",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Have a go at this in your spare time and observe the results:\n",
    "\n",
    " 1. Change the learning rate and batch size in `config`\n",
    " 2. Try chaning the number of workers to 1/2 number of cores on your localhost or laptop\n",
    " 3. Change the `batch_size` and `epochs`\n",
    " 4. Try the second model by changing the `mode_type` in `config` to 1\n",
    " 5. Did it improve the accuracy or minimize the loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73ff3c-26fc-4864-985c-a5da63507b80",
   "metadata": {},
   "source": [
    "### Homework\n",
    "1. Can you try some deep learning regularization techniques to bring the loss down?\n",
    "2. Change a the loss function and test if that help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ff152-b2dc-4b64-86cf-cdaa4f6181f8",
   "metadata": {},
   "source": [
    "ðŸ“– [Back to Table of Contents](../ex_00_tutorial_overview.ipynb)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
