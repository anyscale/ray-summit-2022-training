{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Tour of Ray Core: Ray Actor Tree Pattern\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_05_multiprocess_pool.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_03_remote_classes.ipynb) <br>\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "In this this tutorial, we revisit Ray Actors and learn more about:\n",
    " * Common Ray Actors patterns used in Ray native libraries for writing distributed Actors\n",
    " * How to pass Ray Actors to remote tasks for distributed computing\n",
    "\n",
    "Let's implement a simple example to illustrate this pattern.\n",
    "\n",
    "# Tree of Actors Pattern\n",
    "\n",
    "A common pattern used in Ray libraries [Ray Tune](https://docs.ray.io/en/latest/tune/index.html), [Ray Train](https://docs.ray.io/en/latest/train/train.html), and [RLlib](https://docs.ray.io/en/latest/rllib/index.html) to train models in a parallel or conduct distributed HPO.\n",
    "\n",
    "In this common pattern, tree of actors, a collection of workers as actors, are managed by a supervisor actor. For example, you want to train multiple models, each of a different type, at the same time, while being able to inspect its state during its training.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/tree-of-actors.svg\" width=\"50%\" height=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start Ray‚Ä¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import ray\n",
    "import random\n",
    "from random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0rc1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='2.0.0rc1', ray_commit='321d8717f73995153d4f9abe98678160831090e1', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-17_16-20-12_249826_34957/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-17_16-20-12_249826_34957/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-08-17_16-20-12_249826_34957', 'metrics_export_port': 56070, 'gcs_address': '127.0.0.1:57447', 'address': '127.0.0.1:57447', 'dashboard_agent_listen_port': 52365, 'node_id': 'a7e32edf31a38a17b9eb97b36473d00bd074134a46e44e9a4e30f184'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Supervisor and worker actor pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic model factory utility  \n",
    "\n",
    "This factory generates a few specify type of models (they are fake üòè): regression, classification, or neural network, and will have its respective training function. Each model will be in a particular state  during training. The final state is `DONE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factory function to return an instance of a model type\n",
    "def model_factory(m: str, func: object):\n",
    "    return Model(m, func)\n",
    "\n",
    "# states to inspect or checkpoint\n",
    "STATES = [\"RUNNING\", \"PENDING\", \"DONE\"]\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, m:str, func: object):\n",
    "        self._model = m\n",
    "        self._func = func\n",
    "\n",
    "    def train(self):\n",
    "        # do some training work here for the respective model type\n",
    "        self._func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Worker Actor\n",
    "This worker actor will train each model. When the model's state reaches `DONE`, we stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Worker(object):\n",
    "    def __init__(self, m:str, func: object):\n",
    "        # type of a model: lr, cl, or nn\n",
    "        self._model = m  \n",
    "        self._func = func\n",
    "       \n",
    "    # inspect its current state and return it. For now\n",
    "    # it could be in one of the states\n",
    "    def state(self) -> str:\n",
    "        return random.choice(STATES)\n",
    "    \n",
    "    # Create the model from the factory for this worker and \n",
    "    # do the training by invoking its respective objective function \n",
    "    # for that model\n",
    "    def work(self) -> None:\n",
    "        model_factory(self._model, self._func).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Supervisor Actor \n",
    "The supervisor creates three actors, each with its own respective training model type and its training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define respective model training functions\n",
    "\n",
    "def lf_func():\n",
    "    # do some training work for linear regression\n",
    "    time.sleep(1)\n",
    "    return 0\n",
    "\n",
    "def cl_func():\n",
    "     # do some training work for classification\n",
    "    time.sleep(1)\n",
    "    return 0\n",
    "\n",
    "def nn_func():\n",
    "     # do some training work for neural networks\n",
    "    time.sleep(1)\n",
    "    return 0\n",
    "\n",
    "@ray.remote\n",
    "class Supervisor:\n",
    "    def __init__(self):\n",
    "        # Create three Actor Workers, each by its unique model type and \n",
    "        # their respective training function\n",
    "        self.workers = [Worker.remote(name, func) for (name, func) \n",
    "                        in [(\"lr\", lf_func), (\"cl\",cl_func), (\"nn\", nn_func)]]\n",
    "                        \n",
    "    def work(self):\n",
    "        # do the work \n",
    "        [worker.work.remote() for worker in self.workers]\n",
    "        \n",
    "    def terminate(self):\n",
    "        [ray.kill(worker) for worker in self.workers]\n",
    "        \n",
    "    def state(self):\n",
    "        return ray.get([worker.state.remote() for worker in self.workers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a Actor instance for supervisor and launch its workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(32d950ec0ccf9d2a7535cf0794422421c201b26d0100000001000000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup = Supervisor.remote()\n",
    "\n",
    "# Launch remote actors as workers\n",
    "sup.work.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Ray Dashboard\n",
    "\n",
    "You should see Actors running as process on the workders nodes\n",
    " * Supervisor\n",
    " * Workers\n",
    " \n",
    "Also, click on the `Logical View` to view more metrics and data on individual Ray Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RUNNING', 'RUNNING', 'DONE']\n",
      "['PENDING', 'PENDING', 'RUNNING']\n",
      "['DONE', 'PENDING', 'DONE']\n",
      "['RUNNING', 'DONE', 'RUNNING']\n",
      "['PENDING', 'PENDING', 'RUNNING']\n",
      "['RUNNING', 'DONE', 'PENDING']\n",
      "['DONE', 'PENDING', 'DONE']\n",
      "['DONE', 'DONE', 'DONE']\n"
     ]
    }
   ],
   "source": [
    "# check their status\n",
    "while True:\n",
    "    # Fetch the states of all its workers\n",
    "    states = ray.get(sup.state.remote())\n",
    "    print(states)\n",
    "    # check if all are DONE\n",
    "    result = all('DONE' == e for e in states)\n",
    "    if result:\n",
    "        # Note: Actor processes will be terminated automatically when the initial actor handle goes out of scope in Python. \n",
    "        # If we create an actor with actor_handle = ActorClass.remote(), then when actor_handle goes out of scope and is destroyed, \n",
    "        # the actor process will be terminated. Note that this only applies to the original actor handle created for the actor \n",
    "        # and not to subsequent actor handles created by passing the actor handle to other tasks.\n",
    "        \n",
    "        # kill supervisors' all workers manually, only for illustrtation and demo\n",
    "        sup.terminate.remote()\n",
    "\n",
    "        # kill the supervisor manually, only for illustration and demo\n",
    "        ray.kill(sup)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "What we have demonstrated above is an Actor tree design pattern, commonly used in Ray for writing distributed applications. In particular, Ray's native libraries such as Train, Tune, Serve, and RLib and [Ray AIR's]() components use it for distributed training and tuning trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any questions?\n",
    "\n",
    "Let's look at another example in a similar tree of actors (and tasks) pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Passing Actor handles to Ray Tasks\n",
    "\n",
    "Actors are versatile: they can instantiated and passed to remote Ray tasks or even other actors. \n",
    "\n",
    "Let's consider writing a distributed messaging service, where workers may post messages to update the state of the messaging service. This could be a logging or monitoring service. For example, [WhyLabs](https://www.anyscale.com/blog/running-and-monitoring-distributed-ml-with-ray-and-whylogs) implemented a variation of this usage pattern to monitor Ray Serve deployments. Since tasks and actors are accessiible as Python\n",
    "objects, they can be passed around to other Python classes or functions.\n",
    "\n",
    "You can pass actor handle instances to remote Ray tasks, which can change the actor's \n",
    "state. The `MessageActor` keeps or clears messages, depending on the method\n",
    "invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class MessageActor(object):\n",
    "    def __init__(self):\n",
    "        # Keep the state of all the messages received\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_message(self, message):\n",
    "        self.messages.append(message)\n",
    "    \n",
    "    # reset and clear all messages\n",
    "    def get_and_clear_messages(self):\n",
    "        messages = self.messages\n",
    "        self.messages = []\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a worker doing some specific work, such as updating a DB or posting a tweet or\n",
    "checking a status of a process and then sends a message to the actor.\n",
    "\n",
    "**NOTE**: _Question: What does this remind of you from the previous lessons?_ \n",
    "\n",
    "(PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def worker(message_actor, j):\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        message_actor.add_message.remote(\n",
    "            f\"Message {i} from worker {j}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_actor = MessageActor.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start three worker tasks that update the `MessageActor` service since each Ray task gets the handle to the `MessageActor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectRef(2751d69548dba956ffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(71b133a11e1c461cffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(5d4b8d1788f12d2dffffffffffffffffffffffff0100000001000000)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[worker.remote(message_actor, j) for j in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the workers are already launched, let's get actor's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New messages\n",
      ": ['Message 0 from worker 0.', 'Message 0 from worker 2.', 'Message 0 from worker 1.', 'Message 1 from worker 0.', 'Message 1 from worker 2.', 'Message 1 from worker 1.', 'Message 2 from worker 0.', 'Message 2 from worker 2.', 'Message 2 from worker 1.']\n",
      "New messages\n",
      ": ['Message 3 from worker 0.', 'Message 3 from worker 2.', 'Message 3 from worker 1.']\n",
      "New messages\n",
      ": ['Message 4 from worker 0.', 'Message 4 from worker 2.', 'Message 4 from worker 1.']\n",
      "New messages\n",
      ": ['Message 5 from worker 2.', 'Message 5 from worker 1.', 'Message 5 from worker 0.']\n",
      "New messages\n",
      ": ['Message 6 from worker 0.', 'Message 6 from worker 2.', 'Message 6 from worker 1.']\n",
      "New messages\n",
      ": ['Message 7 from worker 2.', 'Message 7 from worker 1.', 'Message 7 from worker 0.']\n",
      "New messages\n",
      ": ['Message 8 from worker 0.', 'Message 8 from worker 2.', 'Message 8 from worker 1.']\n",
      "New messages\n",
      ": ['Message 9 from worker 0.', 'Message 9 from worker 1.', 'Message 9 from worker 2.']\n",
      "New messages\n",
      ": []\n",
      "New messages\n",
      ": []\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    new_messages = ray.get(message_actor.get_and_clear_messages.remote())\n",
    "    print(\"New messages\\n:\", new_messages)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Add a remote class, such as a logging actor, that keeps states by logging info (may be only in memory) about N experiments, where (N <=3).\n",
    "2. Implement actor methods that alters the state. That is, it tracks results of 9 separate runs per each experiment.\n",
    "3. Write a separate Ray task that executes 9 runs per each experiment.\n",
    "4. Instantiate the actor and call its methods from within the remote Ray task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution hints\n",
    "\n",
    "This solution is just a structural hint. There are few missing bits:\n",
    " * instantiation of `LoggingActor`\n",
    " * Need to use `ray.get()` to fetch the values from the object store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "@ray.remote\n",
    "class LoggingActor(object):\n",
    "    def __init__(self):\n",
    "        self.logs = defaultdict(list)\n",
    "    \n",
    "    def log(self, index, message):\n",
    "        self.logs[index].append(message)\n",
    "    \n",
    "    def get_logs(self):\n",
    "        return dict(self.logs)\n",
    "    \n",
    "@ray.remote\n",
    "def run_experiment(experiment_index, logging_actor):\n",
    "    for i in range(9):\n",
    "        time.sleep(1)\n",
    "        # Push a logging message to the actor.\n",
    "        logging_actor.log.remote(experiment_index, 'On iteration {}'.format(i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging_actor = # TODO Instantiate Actor here\n",
    "experiment_ids = []\n",
    "for i in range(3):\n",
    "    # TODO\n",
    "    # invoke task and append results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logging_actor.get_logs.remote()\n",
    "# TODO use ray.get() to fetch the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "We going to switch a focus little and learn how you can use Ray's replacement\n",
    "for Python's Multiprocessing pool. \n",
    "\n",
    "Let's move on to the [Multiprocessing pool with Ray](ex_05_multiprocess_pool.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. Read references below.\n",
    "2. Can you implement calculating `pi` as a combination of actor (which keeps the state of the progress of calculating `pi` as it approaches its final value) and a task (which  computes candidates for `pi`)? \n",
    "\n",
    "**solution hint**: Check the Ray core quickstart docs only if you need to... :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Writing your First Distributed Python Application with Ray](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray)\n",
    " * [Using and Programming with Actors](https://docs.ray.io/en/latest/actors.html)\n",
    " * [Advanced Patterns and Anti-Patterns in Ray](https://docs.ray.io/en/latest/ray-design-patterns/index.htmlhttps://docs.ray.io/en/latest/ray-design-patterns/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_05_multiprocess_pool.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_03_remote_classes.ipynb) <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
