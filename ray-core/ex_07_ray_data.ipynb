{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89505bc4-70e5-4ed5-9b91-f75804ce40db",
   "metadata": {},
   "source": [
    "# Gentle introduction to Ray datasets APIs\n",
    "\n",
    "© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "### Overview\n",
    "\n",
    "This is a brief introduction to Ray's native library `ray dataset`. As a native Ray library, built atop Ray, it allows you to exchange data among Ray tasks, actors, libraries, and applications. Additionally, Ray datasets provides standard transformations like `map`, `filter`, and `partition`. Ray datasets is *not* a replacement for a full-fledged data processing library EDA, ETL or a subsitute for Apache Spark or Dask or Pandas DataFrames. It's primary objective is last-mile rudimentary data preprocessing and data ingestion for ML training.\n",
    "\n",
    "Supporting myriad [file formats and data sources](https://docs.ray.io/en/latest/data/dataset.html#datasource-compatibility), you can read from and write to local FS and cloud storage. \n",
    "\n",
    "<img src=\"images/dataset.png\" width=\"70%\" height=\"35%\">\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "In this introductory tutorial you will learn:\n",
    " * create, transform, read and save Ray datasets\n",
    " * understand datapipelines and its use\n",
    " * use Ray data for last-mile ML ingestion for your distributed trainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca802b-f3d5-4227-b43c-08fd14878021",
   "metadata": {},
   "source": [
    "### Ray Datasets\n",
    "\n",
    "A Ray dataset implements a distributed [Apache Arrow](https://arrow.apache.org/). A Dataset consists of a list of Ray object references to blocks. Each block holds a set of items in either an [Arrow table](https://arrow.apache.org/docs/python/data.html#tables) or a Python list (for Arrow incompatible objects).\n",
    "\n",
    "<img src=\"images/dataset-arch.png\" width=\"70%\" height=\"35%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273919e-5310-45ff-8ec7-7a1db65a4a93",
   "metadata": {},
   "source": [
    "### Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "048e1661-7411-4ff2-8752-61a564b3987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, random\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c79e3c7-feba-4d77-afc2-c29ae62a4736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='1.12.1', ray_commit='4863e33856b54ccf8add5cbe75e41558850a1b75', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-05-24_17-43-48_949432_96774/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-05-24_17-43-48_949432_96774/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-05-24_17-43-48_949432_96774', 'metrics_export_port': 64567, 'gcs_address': '127.0.0.1:64282', 'address': '127.0.0.1:64282', 'node_id': 'b08f82ca3a745634027e92818d54aa6a247ce6278c638495b9dbf87c'})\n"
     ]
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ctx = ray.init(logging_level=logging.ERROR)\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa0cf1de-71d7-478e-a13e-3c53ae0ab115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard url: http://127.0.0.1:8265\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dashboard url: http://{ctx.address_info['webui_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdbd1d-7083-44b6-918d-de1312af52f2",
   "metadata": {},
   "source": [
    "Let's create a generic dataset of 20K integers and look at the schema and underlying datatype. The difference between `show` and `take` is that the former takes one item at time and prints it, while the latter iterates over rows items from the dataset, appends to a list and returns it. `ds.show()` calls `ds.take()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2460a28-e0dd-4745-b52b-2a66c74c48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, int, None, [0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ray.data.range(20_000)\n",
    "ds.count(), ds.schema(), ds.show(5), ds.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79f73a-b7a5-42f6-bfab-e0db44c13866",
   "metadata": {},
   "source": [
    "Let's create a dataset of Arrow records with three columns and data associated with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0b84110-bcc8-4ea3-bdf2-ff6031caf6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'amount': 1.5,\n",
       "  'interest': 0.1,\n",
       "  'state': 'CA',\n",
       "  'marital_status': 'divorced',\n",
       "  'defaulted': 0,\n",
       "  'gender': 'M'},\n",
       " {'id': 2,\n",
       "  'amount': 3.0,\n",
       "  'interest': 0.1,\n",
       "  'state': 'CA',\n",
       "  'marital_status': 'divorced',\n",
       "  'defaulted': 1,\n",
       "  'gender': 'U'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATES = [\"CA\", \"AZ\", \"OR\", \"WA\", \"TX\", \"UT\"]\n",
    "M_STATUS = [\"married\", \"single\", \"domestic\", \"divorced\", \"undeclared\"]\n",
    "GENDER = [\"F\", \"M\", \"U\"]\n",
    "items = [{\"id\": i, \n",
    "          \"amount\": i * 1.5, \n",
    "          \"interest\": random.randint(1,5) * .1,\n",
    "          \"state\": random.choice(STATES),\n",
    "          \"marital_status\": random.choice(M_STATUS),\n",
    "          \"defaulted\": random.randint(0,1),\n",
    "          \"gender\":random.choice(GENDER) } for i in range(1,500_001)]\n",
    "items[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71a5f028-aa5b-4e40-9d89-c2458eae5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_ds = ray.data.from_items(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8a52903-b132-4c7a-9920-274d5620a3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000,\n",
       " [{'id': 1, 'amount': 1.5, 'interest': 0.1, 'state': 'CA', 'marital_status': 'divorced', 'defaulted': 0, 'gender': 'M'},\n",
       "  {'id': 2, 'amount': 3.0, 'interest': 0.1, 'state': 'CA', 'marital_status': 'divorced', 'defaulted': 1, 'gender': 'U'}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_ds.count(), arrow_ds.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "169d1e5c-4d22-4ec8-98e7-a98e8c977b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.schema of Dataset(num_blocks=200, num_rows=500000, schema={id: int64, amount: double, interest: double, state: string, marital_status: string, defaulted: int64, gender: string})>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_ds.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf52fcd-041c-4008-93db-e86cd8f6fd1c",
   "metadata": {},
   "source": [
    "### Saving datasets\n",
    "Ray datasets support myriad data formats and public storage. Let's save this dataset as a parquet file and create 4 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3dbf30b-79dc-41ee-8aae-204b0fa8cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repartition: 100%|███████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 89.42it/s]\n",
      "Write Progress: 100%|████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 65.13it/s]\n"
     ]
    }
   ],
   "source": [
    "arrow_ds.repartition(5).write_parquet(\"data/interest.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77ca6b26-4a08-44a7-8b9b-5a7582945384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13552\n",
      "-rw-r--r--  1 jules  staff  1399864 May 24 17:44 a6484d528e5a49d481ba95abbfa3a934_000000.parquet\n",
      "-rw-r--r--  1 jules  staff  1384054 May 24 17:44 a6484d528e5a49d481ba95abbfa3a934_000001.parquet\n",
      "-rw-r--r--  1 jules  staff  1382275 May 24 17:44 a6484d528e5a49d481ba95abbfa3a934_000002.parquet\n",
      "-rw-r--r--  1 jules  staff  1381706 May 24 17:44 a6484d528e5a49d481ba95abbfa3a934_000003.parquet\n",
      "-rw-r--r--  1 jules  staff  1381278 May 24 17:44 a6484d528e5a49d481ba95abbfa3a934_000004.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/interest.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180628b1-d64f-44ad-8cb0-961da2a5ca40",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "Ray datasets support transformation in parallel using `map`. It uses ray tasks to execute eagerly. \n",
    "\n",
    "Among others [transformations](https://docs.ray.io/en/latest/data/package-ref.html#dataset-api), it supports`filter`, `flat_map`, `groupBy`etc.\n",
    "\n",
    "Let's try a using `.map()` and `.filter()` on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc9f6e9f-c100-4b6d-9647-340a42686b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [00:02<00:00, 95.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.75, 7.5, 11.25, 15.0, 18.75]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_ds.map(lambda x: x['amount'] * 2.5).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc9b8286-942c-4c9d-af44-44c4b62120d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress: 100%|██████████████████████████████████████████████████████████████████████| 200/200 [00:02<00:00, 88.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 6668, 'amount': 10002.0, 'interest': 0.30000000000000004, 'state': 'CA', 'marital_status': 'undeclared', 'defaulted': 0, 'gender': 'U'},\n",
       " {'id': 6672, 'amount': 10008.0, 'interest': 0.4, 'state': 'CA', 'marital_status': 'undeclared', 'defaulted': 1, 'gender': 'U'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_ds.filter(lambda x: x['amount'] > 10000.00 and x['state'] == 'CA').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dd6ac-6aa0-44dc-91ef-96382725eef9",
   "metadata": {},
   "source": [
    "### Exchanging datasets\n",
    "\n",
    "Datasets can be passed to Ray tasks or actors and read with `.iter_batches()` or `.iter_rows()`. This does not incur a copy, since the blocks of the Dataset are passed by reference as Ray objects.\n",
    "\n",
    "Let's examine how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c83caaaa-6871-4d67-86a3-4c3c6f000c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class BatchWorker:\n",
    "    def __init__(self, rank):\n",
    "        self.rank = rank\n",
    "        self.processed= 0\n",
    "    \n",
    "    @ray.method(num_returns=2)\n",
    "    def process_shard_list(self, shard) -> int:\n",
    "        for batch in shard.iter_batches(batch_size=1024):\n",
    "            # do something with the batch\n",
    "            # maybe create a parquet file \n",
    "            self.processed = self.processed + len(batch)\n",
    "        # return items processed, worker id\n",
    "        return (self.processed, self.rank)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e4b2d-acf0-4f50-90ea-f0b43f9e66f1",
   "metadata": {},
   "source": [
    "#### Create batch workers as Ray actors\n",
    "Each actor will get a shard, list of rows, to work on. We split\n",
    "our dataset `arrow_ds` into five shards. We `BatchWorker` gets a shard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7371d6f7-b46c-42f3-b820-dfe3278bed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_workers = [BatchWorker.remote(i) for i in range(1, 6)]\n",
    "shards = arrow_ds.split(n=5, locality_hints=batch_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a09dcec4-50e3-493c-9a4b-090019d41eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_refs = [w.process_shard_list.remote(s) for w, s in zip(batch_workers, shards)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34e3748a-9aaf-41d0-b770-034b74fa12d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100000, 1], [100000, 2], [100000, 3], [100000, 4], [100000, 5]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [ray.get(ref) for ref in object_refs]\n",
    "values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
