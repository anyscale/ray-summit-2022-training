{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guided Tour of Ray Core: Multiprocessing Pool\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_06_ray_api_calls.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_04_remote_classes_revisited.ipynb) <br>\n",
    "\n",
    "### Learning objectives\n",
    "In this this tutorial, you will learn about:\n",
    "\n",
    " * Ray's replacement for distribtued Python's normal `Multiprocessing.pool` library \n",
    " * Scaling CPU bound tasks using different strategies:\n",
    "   * A serial approach for a CPU bound task\n",
    "   * A multi-threaded approach for a CPU bound task\n",
    "   * A multiprocess approach for a CPU bound task\n",
    "   * A Ray distributed multiprocess appraoch for a CPU bound task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*Distributed multiprocessing.Pool*](https://docs.ray.io/en/latest/multiprocessing.html) makes it easy to scale existing Python applications that use [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html) by leveraging *Ray Actors*. Ray supports running distributed python programs with the **multiprocessing.Pool** API using Ray Actors, each running on a [workder node](https://docs.ray.io/en/latest/ray-core/actors.html#faq-actors-workers-and-resources), instead of local processes. This makes it easy to scale existing applications that use regular `multiprocessing.Pool` from a single node to a cluster.\n",
    "\n",
    "<img src=\"images/dist_multi_pool.png\" width=\"80%\" height=\"55%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have go ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import time\n",
    "import logging\n",
    "import ray\n",
    "from ray.util.multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Pool example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a simple Python function with a slight delay added (to make it behave like a more complex calculation)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be some complicated and compute intensive task\n",
    "def func(x):\n",
    "    time.sleep(1.5)\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute some prime numbers between a range  2-->N\n",
    "def is_prime(n):\n",
    "    for divisor in range(2, int(n ** 0.5) + 1):\n",
    "        if n % divisor == 0:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8269\" target=\"_blank\">http://127.0.0.1:8269</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8269', python_version='3.8.13', ray_version='3.0.0.dev0', ray_commit='{{RAY_COMMIT_SHA}}', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-07-29_10-19-55_462075_1697/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-29_10-19-55_462075_1697/sockets/raylet', 'webui_url': '127.0.0.1:8269', 'session_dir': '/tmp/ray/session_2022-07-29_10-19-55_462075_1697', 'metrics_export_port': 61000, 'gcs_address': '127.0.0.1:61061', 'address': '127.0.0.1:61061', 'dashboard_agent_listen_port': 52365, 'node_id': 'c9ee46d3df689c2bce806fad6ede6c71d480330cd1e278b1c742e3e2'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a *Pool* of Actors and distribute its tasks across a cluster (or across the available cores on a laptop). Let's use Ray's drop-in replacement for [multiprocessing pool](https://docs.ray.io/en/latest/multiprocessing.html) uses Ray Actors to distribute the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "100\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "# Create a Pool of Actors\n",
    "pool = Pool()\n",
    "\n",
    "for result in pool.map(func, range(12)):\n",
    "    time.sleep(2)      # sleep for you to check the dashboard; you should see 10 Actors\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: The distributed version has the trade-off of initial increased overhead, albeit now it can scale-out horizontally across a cluster. The benefits would be more pronounced with a more computationally expensive calculation. In other words, its value is amortized over time with compute-intensive complex operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2000000 \n",
    "lst = list(range(num))\n",
    "results = []\n",
    "pool = Pool(5) # by default it will create pool == number of cores on the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of primes in 2000000 are 148935\n",
      "CPU times: user 3.88 s, sys: 143 ms, total: 4.02 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for result in pool.map(is_prime, lst):\n",
    "    results.append(result)\n",
    "print(f\"Total number of primes in {num} are {sum(results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a compute intensive class that does some matrix\n",
    "computation. Consider this to be a compute intenstive task\n",
    "doing massive tensor transformation or computation.\n",
    "\n",
    "**NOTE**: This will be your excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(n):\n",
    "    # Simulate a long intensive task\n",
    "    #TODO\n",
    "    \n",
    "    # do some matrix computation \n",
    "    # and return results\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Ray remote task that launches `task()` across a pool of Actors on the cluster. It creates\n",
    "a pool of `Ray Actors`, each scheduled on a cluster worker. On a single node or localhost it will be an Actor per CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A long running task doing the work, collecting data, updating the database\n",
    "# create an Actor pool of num_pool workers nodes\n",
    "@ray.remote\n",
    "def launch_long_running_tasks(num_pool):\n",
    "    pool = Pool(num_pool) # num_pool of Actors\n",
    "    results = []\n",
    "    # Iterate over 50 times in batches of 10\n",
    "    # TODO, replace func with task() here for the exercise\n",
    "    for result in pool.map(func, range(1, 51, 10)):\n",
    "        results.append(result)\n",
    "        \n",
    "    # Done so terminate pool\n",
    "    pool.terminate()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Actor like supervisor that launches all these remote tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class LaunchDistributedTasks:\n",
    "    def __init__(self, limit=5):\n",
    "        self._limit = limit\n",
    "\n",
    "    def launch(self):\n",
    "        # launch the remote task\n",
    "        return launch_long_running_tasks.remote(self._limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch our supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched remote jobs\n"
     ]
    }
   ],
   "source": [
    "launcher = LaunchDistributedTasks.remote()\n",
    "print(\"Launched remote jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " list of results :[1, 121, 441, 961, 1681]\n",
      " Total results: 5\n"
     ]
    }
   ],
   "source": [
    "values = ray.get(ray.get(launcher.launch.remote()))\n",
    "print(f\" list of results :{values}\")\n",
    "print(f\" Total results: {len(values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercises\n",
    "\n",
    "1. Can you convert `task()` into a compute-intensive function?\n",
    "2. Use `task()` in `pool.map(task,....)`\n",
    "3. (Optional) Explore the CPU bound tasks using different strategies in this [notebook](extra/mp_all_nb.ipynb) in the `extra` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. Write a Python `multiprocessing.pool` version of `task()`, with a large dataset, and compare the timings with \n",
    "the Ray distributed `multiprocessing.pool`. \n",
    "2. Do you see a difference in timings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step\n",
    "\n",
    "Let's take a tour of the [Ray APIs](ex_06_ray_api_calls.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_06_ray_api_calls.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_04_remote_classes_revisited.ipynb) <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
