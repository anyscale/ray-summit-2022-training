{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e032f0f6-2547-4cc4-ae84-54a53752884d",
   "metadata": {},
   "source": [
    "# Ray Serve - Inference Graphs APIs\n",
    "\n",
    "© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "### Learning Objective:\n",
    "In this introductory tutorial, you will:\n",
    "\n",
    "* construct a simple model composition inference graph pipeline\n",
    "* utilize inference graph APIs to create a single deployment\n",
    "* and score an inference graph end-to-end\n",
    "\n",
    "This tutorial takes a simple example of model composition, built using ServeHandle APIs, and converts it into\n",
    "an equivalent model composition. The example converted from ServeHandle APIs to inference graphs is [here](https://docs.ray.io/en/latest/serve/ml-models.html#id3).\n",
    "\n",
    "<img src=\"../images/model_composition_inference_graph.png\" width=\"50%\" height=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984d870-82b1-4b43-a5fd-c6df6f5f9f6d",
   "metadata": {},
   "source": [
    "import time\n",
    "import asyncio\n",
    "import requests\n",
    "import starlette\n",
    "\n",
    "from random import random\n",
    "import requests\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "from ray.experimental.dag.input_node import InputNode\n",
    "from ray.serve.drivers import DAGDriver\n",
    "from ray.serve.http_adapters import json_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e5c18-5518-46cf-aaf9-e4d65e65ba1e",
   "metadata": {},
   "source": [
    "### Step 1: Build processor nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2245249e-da7c-415f-bf5d-eea4f6a57da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "async def preprocess(input_data):\n",
    "    \"\"\"Simple feature processing that returns int multiplied by the input as a float.\"\"\"\n",
    "    await asyncio.sleep(0.15) # Manual delay for blocking computation\n",
    "    return random() * input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7774ee-adc5-407e-b98f-ddc75ade7d7f",
   "metadata": {},
   "source": [
    "### Step 2: Model nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ad18a6a-22e4-437f-868c-675e3bfd2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class ModelOne:\n",
    "    def __init__(self, input):\n",
    "        self.weight = random()\n",
    "        self.result = self.weight * input\n",
    "        \n",
    "    async def forward(self, input: int):\n",
    "        await asyncio.sleep(0.3) # Manual delay for blocking computation\n",
    "        print(f\"Model 1 called with data:{input}: result: {self.result}\")\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ccbe4a3-6093-40e9-9c93-148c9fc5be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class ModelTwo:\n",
    "    def __init__(self, input):\n",
    "        self.weight = random()\n",
    "        self.result = self.weight * input\n",
    "        \n",
    "    async def forward(self, input: int):\n",
    "        await asyncio.sleep(0.3) # Manual delay for blocking computation\n",
    "        print(f\"Model 2 called with data:{input}: result: {self.result}\")\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3a863-6626-4443-ba9b-6ecd6a57e334",
   "metadata": {},
   "source": [
    "### Step 3: Build over Combiner aggregation based on user input and operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6ace4d1-2e44-4f89-a27a-a9206e6f2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "class Combiner:\n",
    "    def __init__(self, m1:ModelOne, m2:ModelTwo):\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        \n",
    "    async def run(self, req_part):\n",
    "        # Submit to model-1 for inference\n",
    "        rst = self.m1.forward.remote(req_part)\n",
    "\n",
    "        # Async gathering of model forward results for request data\n",
    "        score = await asyncio.gather(rst)\n",
    "        if score[0] >= 0.5:\n",
    "            rst = self.m2.forward.remote(req_part)\n",
    "            await asyncio.gather(rst)\n",
    "            result = {\"model_used: 1 & 2;  score\": score}\n",
    "        else:\n",
    "            result = {\"model_used: 1 ; score\": score}\n",
    "            \n",
    "        return result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307a8d3-0e14-44e1-ac8a-86903617c079",
   "metadata": {},
   "source": [
    "### Step 4: Build our InputNode and driver deployment to handle http ingress¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74d5ae1f-7ff5-4269-9c8c-d748a26d4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "with InputNode() as dag_input:\n",
    "    \n",
    "    # create a preprocessor\n",
    "    pre_prop = preprocess.bind(dag_input[0])\n",
    "    \n",
    "    # create two models nodes\n",
    "    model_1 = ModelOne.bind(1)\n",
    "    model_2 = ModelTwo.bind(2)\n",
    "    \n",
    "    # create the combiner\n",
    "    combiner = Combiner.bind(model_1, model_2)\n",
    "    \n",
    "    # Use output of function DeploymentNode in bind()\n",
    "    dag = combiner.run.bind(pre_prop)\n",
    "    \n",
    "    # Each serve dag has a driver deployment as ingress that can be user provided.\n",
    "    serve_dag = DAGDriver.options(route_prefix=\"/my-dag\", num_replicas=2).bind(\n",
    "        dag, http_adapter=json_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350e2ad-7638-4ee3-a504-f63325b488eb",
   "metadata": {},
   "source": [
    "### Step 5: Test the full DAG in both python and http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44897481-89a2-4eaa-9e17-3c75f82185d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,040 controller 97331 checkpoint_path.py:17 - Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,145 controller 97331 http_state.py:112 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-node:127.0.0.1-0' on node 'node:127.0.0.1-0' listening on '127.0.0.1:8000'\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,669 controller 97331 deployment_state.py:1216 - Adding 1 replicas to deployment 'preprocess'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,675 controller 97331 deployment_state.py:1216 - Adding 1 replicas to deployment 'ModelOne'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,680 controller 97331 deployment_state.py:1216 - Adding 1 replicas to deployment 'ModelTwo'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,686 controller 97331 deployment_state.py:1216 - Adding 1 replicas to deployment 'Combiner'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:06:28,691 controller 97331 deployment_state.py:1216 - Adding 2 replicas to deployment 'DAGDriver'.\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO:     Started server process [97333]\n",
      "You are retrieving a sync handle inside an asyncio loop. Try getting client.get_handle(.., sync=False) to get better performance. Learn more at https://docs.ray.io/en/master/serve/http-servehandle.html#sync-and-async-handles\n"
     ]
    }
   ],
   "source": [
    "dag_handle = serve.run(serve_dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528eacf9-1eda-4507-a6a7-9a8d9c44f6a6",
   "metadata": {},
   "source": [
    "### Use HTTP endpoint\n",
    "\n",
    "Send a bunch of HTTP requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50ce4901-f61b-4cd9-bbf9-0ff23d1a44fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:47,593 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 307 6.1ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97339)\u001b[0m INFO 2022-07-06 14:06:47,592 DAGDriver DAGDriver#Haucbp replica.py:478 - HANDLE __call__ OK 0.3ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m You are retrieving a sync handle inside an asyncio loop. Try getting client.get_handle(.., sync=False) to get better performance. Learn more at https://docs.ray.io/en/master/serve/http-servehandle.html#sync-and-async-handles\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m You are retrieving a sync handle inside an asyncio loop. Try getting client.get_handle(.., sync=False) to get better performance. Learn more at https://docs.ray.io/en/master/serve/http-servehandle.html#sync-and-async-handles\n",
      "\u001b[2m\u001b[36m(preprocess pid=97335)\u001b[0m INFO 2022-07-06 14:06:47,761 preprocess preprocess#iGqPMH replica.py:478 - HANDLE __call__ OK 151.7ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m You are retrieving a sync handle inside an asyncio loop. Try getting client.get_handle(.., sync=False) to get better performance. Learn more at https://docs.ray.io/en/master/serve/http-servehandle.html#sync-and-async-handles\n",
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m INFO 2022-07-06 14:06:48,096 ModelOne ModelOne#OLADpC replica.py:478 - HANDLE forward OK 301.3ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m You are retrieving a sync handle inside an asyncio loop. Try getting client.get_handle(.., sync=False) to get better performance. Learn more at https://docs.ray.io/en/master/serve/http-servehandle.html#sync-and-async-handles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m Model 1 called with data:0.0: result: 0.5773534453760967\n",
      "{\"model_used: 1 & 2;  score\":[0.5773534453760967]}\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m Model 2 called with data:0.0: result: 1.1547068907521933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:48,425 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 200 830.7ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:48,441 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 307 6.2ms\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m INFO 2022-07-06 14:06:48,411 ModelTwo ModelTwo#zCWcFH replica.py:478 - HANDLE forward OK 302.2ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97339)\u001b[0m INFO 2022-07-06 14:06:48,439 DAGDriver DAGDriver#Haucbp replica.py:478 - HANDLE __call__ OK 0.5ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m INFO 2022-07-06 14:06:48,416 Combiner Combiner#EVWrVn replica.py:478 - HANDLE run OK 645.6ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m INFO 2022-07-06 14:06:48,420 DAGDriver DAGDriver#YQhOiE replica.py:478 - HANDLE __call__ OK 823.9ms\n",
      "\u001b[2m\u001b[36m(preprocess pid=97335)\u001b[0m INFO 2022-07-06 14:06:48,605 preprocess preprocess#iGqPMH replica.py:478 - HANDLE __call__ OK 151.5ms\n",
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m INFO 2022-07-06 14:06:48,930 ModelOne ModelOne#OLADpC replica.py:478 - HANDLE forward OK 303.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m Model 1 called with data:0.6082014745761107: result: 0.5773534453760967\n",
      "{\"model_used: 1 & 2;  score\":[0.5773534453760967]}\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m Model 2 called with data:0.6082014745761107: result: 1.1547068907521933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:49,248 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 200 804.2ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:49,254 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 307 2.6ms\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m INFO 2022-07-06 14:06:49,244 ModelTwo ModelTwo#zCWcFH replica.py:478 - HANDLE forward OK 300.7ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97339)\u001b[0m INFO 2022-07-06 14:06:49,253 DAGDriver DAGDriver#Haucbp replica.py:478 - HANDLE __call__ OK 0.2ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m INFO 2022-07-06 14:06:49,246 Combiner Combiner#EVWrVn replica.py:478 - HANDLE run OK 627.3ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m INFO 2022-07-06 14:06:49,247 DAGDriver DAGDriver#YQhOiE replica.py:478 - HANDLE __call__ OK 801.3ms\n",
      "\u001b[2m\u001b[36m(preprocess pid=97335)\u001b[0m INFO 2022-07-06 14:06:49,412 preprocess preprocess#iGqPMH replica.py:478 - HANDLE __call__ OK 151.2ms\n",
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m INFO 2022-07-06 14:06:49,717 ModelOne ModelOne#OLADpC replica.py:478 - HANDLE forward OK 301.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m Model 1 called with data:1.1953268734127345: result: 0.5773534453760967\n",
      "{\"model_used: 1 & 2;  score\":[0.5773534453760967]}\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m Model 2 called with data:1.1953268734127345: result: 1.1547068907521933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:50,040 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 200 784.9ms\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m INFO 2022-07-06 14:06:50,028 ModelTwo ModelTwo#zCWcFH replica.py:478 - HANDLE forward OK 303.3ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m INFO 2022-07-06 14:06:50,034 Combiner Combiner#EVWrVn replica.py:478 - HANDLE run OK 620.7ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m INFO 2022-07-06 14:06:50,036 DAGDriver DAGDriver#YQhOiE replica.py:478 - HANDLE __call__ OK 780.0ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:50,050 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 307 4.2ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97339)\u001b[0m INFO 2022-07-06 14:06:50,048 DAGDriver DAGDriver#Haucbp replica.py:478 - HANDLE __call__ OK 0.4ms\n",
      "\u001b[2m\u001b[36m(preprocess pid=97335)\u001b[0m INFO 2022-07-06 14:06:50,210 preprocess preprocess#iGqPMH replica.py:478 - HANDLE __call__ OK 151.3ms\n",
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m INFO 2022-07-06 14:06:50,518 ModelOne ModelOne#OLADpC replica.py:478 - HANDLE forward OK 301.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m Model 1 called with data:1.1364933874902587: result: 0.5773534453760967\n",
      "{\"model_used: 1 & 2;  score\":[0.5773534453760967]}\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m Model 2 called with data:1.1364933874902587: result: 1.1547068907521933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:50,831 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 200 778.8ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:50,838 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 307 2.3ms\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m INFO 2022-07-06 14:06:50,827 ModelTwo ModelTwo#zCWcFH replica.py:478 - HANDLE forward OK 301.4ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97339)\u001b[0m INFO 2022-07-06 14:06:50,837 DAGDriver DAGDriver#Haucbp replica.py:478 - HANDLE __call__ OK 0.2ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m INFO 2022-07-06 14:06:50,828 Combiner Combiner#EVWrVn replica.py:478 - HANDLE run OK 616.1ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m INFO 2022-07-06 14:06:50,830 DAGDriver DAGDriver#YQhOiE replica.py:478 - HANDLE __call__ OK 775.7ms\n",
      "\u001b[2m\u001b[36m(preprocess pid=97335)\u001b[0m INFO 2022-07-06 14:06:50,997 preprocess preprocess#iGqPMH replica.py:478 - HANDLE __call__ OK 151.6ms\n",
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m INFO 2022-07-06 14:06:51,321 ModelOne ModelOne#OLADpC replica.py:478 - HANDLE forward OK 301.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ModelOne pid=97336)\u001b[0m Model 1 called with data:2.4201230515254943: result: 0.5773534453760967\n",
      "{\"model_used: 1 & 2;  score\":[0.5773534453760967]}\n",
      "CPU times: user 92.9 ms, sys: 35.8 ms, total: 129 ms\n",
      "Wall time: 4.07 s\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m Model 2 called with data:2.4201230515254943: result: 1.1547068907521933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=97333)\u001b[0m INFO 2022-07-06 14:06:51,641 http_proxy 127.0.0.1 http_proxy.py:310 - POST /my-dag 200 801.2ms\n",
      "\u001b[2m\u001b[36m(ModelTwo pid=97337)\u001b[0m INFO 2022-07-06 14:06:51,635 ModelTwo ModelTwo#zCWcFH replica.py:478 - HANDLE forward OK 300.9ms\n",
      "\u001b[2m\u001b[36m(Combiner pid=97338)\u001b[0m INFO 2022-07-06 14:06:51,637 Combiner Combiner#EVWrVn replica.py:478 - HANDLE run OK 632.0ms\n",
      "\u001b[2m\u001b[36m(DAGDriver pid=97340)\u001b[0m INFO 2022-07-06 14:06:51,638 DAGDriver DAGDriver#YQhOiE replica.py:478 - HANDLE __call__ OK 797.3ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(5):\n",
    "    print(requests.post(\"http://127.0.0.1:8000/my-dag\", json=[i]).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78f85ef4-b447-46d4-aec2-586180c1a864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:07:01,050 controller 97331 deployment_state.py:1240 - Removing 1 replicas from deployment 'preprocess'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:07:01,052 controller 97331 deployment_state.py:1240 - Removing 1 replicas from deployment 'ModelOne'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:07:01,053 controller 97331 deployment_state.py:1240 - Removing 1 replicas from deployment 'ModelTwo'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:07:01,056 controller 97331 deployment_state.py:1240 - Removing 1 replicas from deployment 'Combiner'.\n",
      "\u001b[2m\u001b[36m(ServeController pid=97331)\u001b[0m INFO 2022-07-06 14:07:01,057 controller 97331 deployment_state.py:1240 - Removing 2 replicas from deployment 'DAGDriver'.\n"
     ]
    }
   ],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
