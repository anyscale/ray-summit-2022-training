{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning development & deployment with Ray AI Runtime (Ray AIR)\n",
    "\n",
    "¬© 2021-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "<img src=\"./images/ray-serve.png\" height=\"30%\" width=\"60%\">\n",
    "\n",
    "## About This Tutorial\n",
    "\n",
    "This modular tutorial will focus on [Ray Serve](https://docs.ray.io/en/latest/serve/index.html), which is a framework-agnostic and Python-first machine learning model serving library built on top of Ray. This tutorial will cover how Ray Serve makes it easy to deploy, scale, and operate a machine learning model using Ray Serve APIs. Divided into three modules, each module will take about an hour, combined with lecture and followed by \n",
    "hands-on üë©‚Äçüíª exercises in class.\n",
    "\n",
    "### Key learnings:\n",
    " \n",
    "* üë© Understand Ray Serve architecture, components, and flow of requests across replicas\n",
    "* üìñ Learn how to use Ray Serve APIs to create, access, and deploy your models and mechanisms to access model deployments via Python APIs and HTTP endpoints\n",
    "* üßë‚ÄçüíªImplement common model deployment patterns for serving ML models using the inference graph API as a directed acyclic graph (DAG)\n",
    "* üìà Scale up/down individual components of an inference graph node, utilizing appropriate hardware resources (GPUs/CPUs) and replicas\n",
    "* üéõ Inspect load and deployments in a Ray dashboard\n",
    "* ‚öôÔ∏è Understand deployment and operational aspects of serving\n",
    "\n",
    "\n",
    "See the instructions in the [README](../README.md) for setting up your environment to use this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     | Lesson | Description |\n",
    "| :-- | :----- | :---------- |\n",
    "|     | **Module 1** | **Introduction Ray Serve and model deployments** |\n",
    "|     | Table of contents | Overview of this tutorial. |\n",
    "| 01  | [Ray Serve Model Serving Challenges](ex_01_model_serving_challenges.ipynb) | What are model serving challenges |\n",
    "| 02  | [Ray Serve and FastAPI Integration - (Optional)](ex_02_ray_serve_fastapi.ipynb) | A simple XGBoost model trained, deployed, and accesses via FastAPI endpoints |\n",
    "| 03  | [Ray Serve Model Composition](ex_03_model_composition.ipynb) | Model composition model deployment pattern|\n",
    "|     | **Module 2** | **Deployment Graph APIs to build inference graphs or DAGs** |\n",
    "| 04  | [Ray Serve Inference Graphs](ex_04_inference_graphs.ipynb) | What are Inference Grahps and how to use the APIs |\n",
    "|     | **Module 3** | **TBD** |\n",
    "| 06  | [Ray Serve Dev to Prod Workflow](ex_05_dev_to_prod.ipynb) | Development to Production Workflow in Ray Serve |\n",
    "| 05  | [TBD]() | TBD |\n",
    "|     | **Extras** | **TBD** |\n",
    "| extra_1  | [Ray Serve Simple Inference Graph](extras/simple_inference_graph.ipynb) | A simple example of deployment graph |\n",
    "| extra_2  | [Ray Serve Simple Composition Inference Graph](extras/.ipynb) | A simple example of deployment graph |\n",
    "| extra_3  | [Ray Serve and MLflow Integration](extras/ray_serve_mlflow.ipynb) | MLflow Integration with Ray Serve |\n",
    "| extra_4  | [Ray Serve End to End Example](extras/ray_serve_end_to_end.ipynb) | An end-to-end example using XGBoost, Tune, and Serve for classification model using diabetes dataset |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
