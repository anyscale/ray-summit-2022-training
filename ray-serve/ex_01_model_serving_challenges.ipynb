{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Serve - Model Serving Challenges\n",
    "\n",
    "Â© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "ðŸ“– [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "âž¡ [Next notebook](./ex_02_ray_serve_fastapi.ipynb) <br>\n",
    "\n",
    "### Learning Objective:\n",
    "In this introductory tutorial, you will:\n",
    "\n",
    "* Learn about model serving challenges\n",
    "* Understand Ray Architecture\n",
    "* Explore the fundamentals of Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The Challenges of Model Serving\n",
    "\n",
    "Model development happens in a data science research environment. There are many challenges, such as feature engineering, model selection, missing or messy data, yet there are tools at the data scientists' disposal. By contrast, model deployment to production faces an entirely different set of challenges and requires different tools. We must bridge the divide as much as possible.\n",
    "\n",
    "So what are some of the challenges of model serving?\n",
    "\n",
    "<img src=\"images/serve_challenges.png\" width=\"70%\" height=\"40%\">\n",
    "\n",
    "### 1. It Should Be Framework Agnostic\n",
    "\n",
    "First, model serving frameworks must be able to serve models from popular frameworks and libraries like TensorFlow, PyTorch, scikit-learn, or even arbitrary Python functions. Even within the same organization, it is common to use several machine learning frameworks, in order to get the best model. \n",
    "\n",
    "Second, machine learning models are typically surrounded by (or work in conjunction with) \n",
    "lots of application or business logic. For example, some model serving is implemented as a RESTful service to which scoring requests are made. Often this is too restrictive, as some additional processing, such as fetching additional data from a online feature store, to augment the request data, may be desired as part of the scoring process, and the performance overhead of remote calls may be suboptimal.\n",
    "\n",
    "### 2. Pure Python or Pythonic\n",
    "\n",
    "In general, model serving should be intuitive for developers and simple to configure and run. Hence, it is desirable to use pure Python and to avoid verbose configurations using YAML files or other means. \n",
    "\n",
    "Data scientists and engineers use Python and Python-based ML frameworks to develop their machine learning models, so they should also be able to use Python to deploy their machine learning applications. This need is growing more critical as online learning applications combine training and serving in the same applications.\n",
    "\n",
    "### 3. Simple and Scalable\n",
    "\n",
    "Model serving must be simple to scale on demand across many machines. It must also be easy to upgrade models dynamically, over time. Achieving production uptime and performance requirements are essential for success.\n",
    "\n",
    "### 4. DevOps/MLOps Integrations\n",
    "\n",
    "Model serving deployments need to integrate with existing \"DevOps\" CI/CD practices for controlled, audited, and predicatble releases. Patterns like [Canary Deployment](https://martinfowler.com/bliki/CanaryRelease.html) are particularly useful for testing the efficacy of a new model before replacing existing models, just as this pattern is useful for other software deployments.\n",
    "\n",
    "### 5. Flexible Deployment Patterns\n",
    "\n",
    "There are unique deployment patterns, too. For example, it should be easy to deploy a forest of models, to split traffic to different instances, and to score data in batches for greater efficiency.\n",
    "\n",
    "See also this [Ray blog post](https://medium.com/distributed-computing-with-ray/the-simplest-way-to-serve-your-nlp-model-in-production-with-pure-python-d42b6a97ad55) on the challenges of model serving and the way Ray Serve addresses them. It also provides an example of starting with a simple model, then deploying a more sophisticated model into the running application. Along the same lines, this blog post, [Serving ML Models in Production Common Patterns](https://www.anyscale.com/blog/serving-ml-models-in-production-common-patterns) discusses how deployment patterns for model serving and how you can use Ray Serve. Additionally, listen to this webinar: [Building a scalable ML model serving API with Ray Serve](https://www.anyscale.com/events/2021/09/09/building-a-scalable-ml-model-serving-api-with-ray-serve). This introductory webinar highlights how Ray Serve makes it easy to deploy, operate and scale a machine learning API.\n",
    "\n",
    "<img src=\"images/PatternsMLProduction.png\" width=\"70%\" height=\"40%\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Ray Serve?\n",
    "\n",
    "[Ray Serve](https://docs.ray.io/en/latest/serve/index.html) is a scalable, framework-agnostic and Python-first model serving library built on [Ray](https://ray.io).\n",
    "\n",
    "<img src=\"images/ray_serve_overview.png\" width=\"70%\" height=\"40%\"> \n",
    "\n",
    "For users, Ray Serve offers these benefits:\n",
    "\n",
    "* **Framework Agnostic**: You can use the same toolkit to serve everything from deep learning models built with [PyTorch](https://docs.ray.io/en/latest/serve/tutorials/pytorch.html#serve-pytorch-tutorial), [Tensorflow](https://docs.ray.io/en/latest/serve/tutorials/tensorflow.html#serve-tensorflow-tutorial), or [Keras](https://docs.ray.io/en/latest/serve/tutorials/tensorflow.html#serve-tensorflow-tutorial), to [scikit-Learn](https://docs.ray.io/en/latest/serve/tutorials/sklearn.html#serve-sklearn-tutorial) models, to arbitrary business logic.\n",
    "* **Python First:** Configure your model serving with pure Python code. No YAML or JSON configurations required.\n",
    "\n",
    "Since Serve is built on Ray, it also allows you to scale to many machines, in your datacenter or in cloud environments, and it allows you to leverage all of the other Ray frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Serve Architecture and components\n",
    "\n",
    "<img src=\"images/serve-architecture-2.0.png\" height=\"40%\" width=\"70%\">\n",
    "\n",
    "There are three kinds of actors that are created to make up a Serve instance:\n",
    "- **Controller**: A global actor unique to each Serve instance that manages\n",
    "  the control plane. The Controller is responsible for creating, updating, and\n",
    "  destroying other actors. Serve API calls like creating or getting a deployment\n",
    "  make remote calls to the Controller.\n",
    "- **HTTP Proxy**: By default there is one HTTP proxy actor on the head node. This actor runs a [Uvicorn](https://www.uvicorn.org/) HTTP\n",
    "  server that accepts incoming requests, forwards them to replicas, and\n",
    "  responds once they are completed.  For scalability and high availability,\n",
    "  you can also run a proxy on each node in the cluster via the `location` field of [`http_options`](core-apis).\n",
    "- **Replicas**: Actors that actually execute the code in response to a\n",
    "  request. For example, they may contain an instantiation of an ML model. Each\n",
    "  replica processes individual requests from the HTTP proxy (these may be batched\n",
    "  by the replica using `@serve.batch`, see the [batching](https://docs.ray.io/en/latest/serve/ml-models.html#serve-batching) docs).\n",
    "\n",
    "For more details, see this [key concepts](https://docs.ray.io/en/latest/serve/index.html) and [architecture](https://docs.ray.io/en/latest/serve/architecture.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifetime of a Request\n",
    "\n",
    "When an HTTP request is sent to the router, the following things happen:\n",
    "\n",
    " * The HTTP request is received and parsed.\n",
    "\n",
    " * The correct deployment associated with the HTTP url path is looked up. The request is placed on a queue.\n",
    "\n",
    " * For each request in a deployment queue, an available replica is looked up and the request is sent to it. If there are no available replicas (there are more than max_concurrent_queries requests outstanding), the request is left in the queue until an outstanding request is finished.\n",
    "\n",
    "Each replica maintains a queue of requests and executes one at a time, possibly using asyncio to process them concurrently. If the handler (the function for the deployment or __call__) is async, the replica will not wait for the handler to run; otherwise, the replica will block until the handler returns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Ray Serve Examples\n",
    "\n",
    "__Deployments__ are the basic unit of request handling in Serve. Each Deployment maintains multiple identical _replicas_, and forwards requests at random to each one. Deployments scale by adding more replicas to respond to traffic faster.\n",
    "\n",
    "In this lesson, we will explore the fundamentals of Deployments. All of the other concepts in Serve build on top of deployments, so it is important to understand them well! \n",
    "\n",
    "If this all feels a bit basic, don't worry: we'll build a functional ML Pipeline later in the course, and handle details such as HTTP parsing and model composition. For now, let's see how Ray Serve makes deployments simple! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray imports\n",
    "import ray\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.7.7</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://172.18.0.35:8265\" target=\"_blank\">http://172.18.0.35:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='172.18.0.35:8265', python_version='3.7.7', ray_version='3.0.0.dev0', ray_commit='13f43b939a43c2dc55cd0330fc0ca2cc57b4ad37', address_info={'node_ip_address': '172.18.0.35', 'raylet_ip_address': '172.18.0.35', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-10_11-03-17_771557_18/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-10_11-03-17_771557_18/sockets/raylet', 'webui_url': '172.18.0.35:8265', 'session_dir': '/tmp/ray/session_2022-08-10_11-03-17_771557_18', 'metrics_export_port': 56832, 'gcs_address': '172.18.0.35:9031', 'address': '172.18.0.35:9031', 'dashboard_agent_listen_port': 52365, 'node_id': '1ee37389f2213fec8190af7a2e84cfd9b79f1d83aec9ece89cdbab04'})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start ray\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "ray.init(logging_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World: A minimal example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our first deployment. The `@serve.deployment` decorator transforms a python function into a deployment. In this case, the `hello()` function will be invoked when the `/hello` HTTP endpoint is hit.\n",
    "\n",
    "The `hello` deployment just says \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our first deployment. The `@serve.deployment` decorator transforms a python function into a deployment. This  In this case, the `hello()` function will be invoked when the HTTP end\n",
    "\n",
    "The `hello` deployment just says \"Hello World!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment\n",
    "def hello():\n",
    "    return \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy our model using Ray Serve.\n",
    "\n",
    "First call `hello.bind()` to get a lazy handle to the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_handle = hello.bind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call `serve.run` to start a server listening on `localhost:8000`, register the `hello` deployment to handle requests sent to the `/hello` endpoint, and to get a live handle to the running deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_handle = serve.run(lazy_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run `serve status` from the command line to see the status of the deployment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_status:\n",
      "  status: RUNNING\n",
      "  message: ''\n",
      "  deployment_timestamp: 0.0\n",
      "deployment_statuses:\n",
      "- name: hello\n",
      "  status: HEALTHY\n",
      "  message: ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Help Jupyter find the serve CLI\n",
    "export PATH=\"/home/ray/anaconda3/bin:$PATH\"\n",
    "\n",
    "serve status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see output similar to the text below if your deployment worked."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "app_status:\n",
    "  status: RUNNING\n",
    "  message: ''\n",
    "  deployment_timestamp: 0.0\n",
    "deployment_statuses:\n",
    "- name: hello\n",
    "  status: HEALTHY\n",
    "  message: ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 ways to query a deployment with Ray Serve. You can either use the handle or send an HTTP request to the appropriate endpoint. In this case, we need to send a GET request to `http://localhost:8000/hello` to hit our endpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query with Ray API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query using Ray handle\n",
    "await hello_handle.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query with the HTTP API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the requests library\n",
    "import requests\n",
    "\n",
    "\n",
    "# Ray Serve runs on port 8000 by default\n",
    "SERVE_URL = \"http://localhost:8000\"\n",
    "\n",
    "def http_get(path: str):\n",
    "    \"\"\"Send a GET request with the requests library\"\"\"\n",
    "    return requests.get(SERVE_URL + path).text\n",
    "\n",
    "# Query using HTTP\n",
    "http_get('/hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query with Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from BiggerFasterFibonacci! The 32nd fibonacci number is 3524578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-08-11 21:28:14--  http://localhost:8000/hello\n",
      "Resolving localhost (localhost)... 127.0.0.1, ::1\n",
      "Connecting to localhost (localhost)|127.0.0.1|:8000... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: â€˜STDOUTâ€™\n",
      "\n",
      "     0K                                                        9.73M=0s\n",
      "\n",
      "2022-08-11 21:28:15 (9.73 MB/s) - written to stdout [70]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -O - 'http://localhost:8000/hello' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We have successfully created, deployed, and queried a minimal model using Ray Serve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fibonacci: Scaling a simple compute intensive task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will demonstrate how Ray Serve makes it easy to scale compute intensive workloads across multiple CPUs. We will use a toy Fibonacci example to show how Serve supports initializing a model at deploy time, and then running compute intensive inferences with that model at request time.\n",
    "\n",
    "**Problem**: Create a deployment that\n",
    "1. At initialization: Accepts a name and records it. Initialize a ComputeIntensiveModel\n",
    "2. At query time: Run the `ComputeIntensiveModel.forward()` helper function, and return the result, along with it's name.\n",
    "3. Handles 3 QPS\n",
    "\n",
    "`ComputeIntensiveModel.forward()` calculates a large fibonacci number (very) inefficiently to simulate running inference on a large ML model. It is CPU bound, and consumes real CPU resources. \n",
    "\n",
    "Most other python serving frameworks optimize QPS by concurrently handling several requests on a single CPU, which works well for IO-bound tasks that have a lot of idle time. This approach doesn't help scale CPU-bound workloads. The only way to scale CPU-bound workloads to high QPS is to use more CPUs.\n",
    "\n",
    "\n",
    "In this example, we show how Ray Serve makes it easy to scale to leverage more compute and deliver higher QPS on compute bound tasks.\n",
    "\n",
    "Let's start by timing `ComputeIntensiveModel.forward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 s Â± 27.7 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from helper import ComputeIntensiveModel\n",
    "\n",
    "model = ComputeIntensiveModel()\n",
    "%timeit model.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each invocation should take around 1.2 seconds to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our `serve.deployment` decorator on a class. The initializer of the class will be called at __deploy__ time, and the `__call__` magic method will be called when the deployment receives a request. \n",
    "\n",
    "Let's initialize our model in the initializer, and then call `model.forward()` function to the `__call__` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import compute_intensive_workload\n",
    "\n",
    "@serve.deployment\n",
    "class Fibonacci:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.model = ComputeIntensiveModel()\n",
    "\n",
    "    def __call__(self):\n",
    "        return f\"Hello from {self.name}! \" + self.model.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy `Fibonacci` with 1 replica. We specify the number of replicas in the `.options()` method on the class. We then pass the constructor arguments, in this case just `name`, to the `.bind()` function to obtain a lazy handle. As before, calling `serve.run` will deploy our model and return a live handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_handle = Fibonacci.options(num_replicas=1).bind(name=\"Fibonacci\")\n",
    "fib_handle = serve.run(lazy_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the status again to make sure our model is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_status:\n",
      "  status: RUNNING\n",
      "  message: ''\n",
      "  deployment_timestamp: 0.0\n",
      "deployment_statuses:\n",
      "- name: Fibonacci\n",
      "  status: HEALTHY\n",
      "  message: ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Help Jupyter find the serve CLI\n",
    "export PATH=\"/home/ray/anaconda3/bin:$PATH\"\n",
    "\n",
    "serve status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse the `http_get` helper defined in the previous section to send an HTTP request to our deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello from BiggerFasterFibonacci! The 32nd fibonacci number is 3524578'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http_get('/Fibonacci')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Measuring QPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a load test against our deployment to measure QPS. \n",
    "\n",
    "We will use the `load_test` function from the helper file, which hits a specified endpoint with a specified number of concurrent requests and returns the measured QPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running load test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent 10 requests in 11.824367761611938. 0.846 QPS average. 1.182s per request.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from helper import load_test\n",
    "\n",
    "# Run 10 queries in parallel and calculate QPS for 1 replica\n",
    "qps_1 = await load_test('/Fibonacci', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 1 replica, so we are only able to serve a little less than 1 QPS.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part! Let's scale up the Fibonacci model to improve throughput. We want to hit 3 QPS, so we will need roughly 5 replicas. Let's also increase the number of requests sent to get a more accurate measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 20:46:51,715\tINFO worker.py:1203 -- Using address localhost:9031 set in the environment variable RAY_ADDRESS\n",
      "2022-08-11 20:46:51,717\tINFO worker.py:1312 -- Connecting to existing Ray cluster at address: 172.18.0.35:9031...\n",
      "2022-08-11 20:46:51,723\tINFO worker.py:1487 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m172.18.0.35:8265\u001b[39m\u001b[22m.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m INFO 2022-08-11 20:46:53,585 controller 2055228 http_state.py:132 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-1ee37389f2213fec8190af7a2e84cfd9b79f1d83aec9ece89cdbab04' on node '1ee37389f2213fec8190af7a2e84cfd9b79f1d83aec9ece89cdbab04' listening on '127.0.0.1:8000'\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m INFO 2022-08-11 20:46:55,544 controller 2055228 deployment_state.py:1233 - Adding 5 replicas to deployment 'Fibonacci'.\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO:     Started server process [2055271]\n",
      "Running load test:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055321)\u001b[0m INFO 2022-08-11 20:47:00,933 Fibonacci Fibonacci#vyAavR replica.py:487 - HANDLE __call__ OK 1401.4ms\n",
      "Running load test:   5%|â–Œ         | 1/20 [00:01<00:27,  1.44s/it]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:00,950 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 1430.3ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:01,036 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 1515.6ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055326)\u001b[0m INFO 2022-08-11 20:47:01,030 Fibonacci Fibonacci#ILFnHy replica.py:487 - HANDLE __call__ OK 1504.1ms\n",
      "Running load test:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  3.87it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:01,203 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 1683.4ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:01,214 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 1695.2ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:01,324 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 1807.2ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055332)\u001b[0m INFO 2022-08-11 20:47:01,212 Fibonacci Fibonacci#awPdXK replica.py:487 - HANDLE __call__ OK 1690.0ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055320)\u001b[0m INFO 2022-08-11 20:47:01,322 Fibonacci Fibonacci#ygQSdT replica.py:487 - HANDLE __call__ OK 1801.6ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055331)\u001b[0m INFO 2022-08-11 20:47:01,195 Fibonacci Fibonacci#ionSkK replica.py:487 - HANDLE __call__ OK 1664.4ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:02,609 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 3089.1ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055321)\u001b[0m INFO 2022-08-11 20:47:02,600 Fibonacci Fibonacci#vyAavR replica.py:487 - HANDLE __call__ OK 1666.4ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055332)\u001b[0m INFO 2022-08-11 20:47:02,882 Fibonacci Fibonacci#awPdXK replica.py:487 - HANDLE __call__ OK 1668.2ms\n",
      "Running load test:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:03<00:06,  1.93it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:03,070 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 3545.1ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055320)\u001b[0m INFO 2022-08-11 20:47:03,067 Fibonacci Fibonacci#ygQSdT replica.py:487 - HANDLE __call__ OK 1742.8ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055331)\u001b[0m INFO 2022-08-11 20:47:03,063 Fibonacci Fibonacci#ionSkK replica.py:487 - HANDLE __call__ OK 1867.6ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055326)\u001b[0m INFO 2022-08-11 20:47:03,225 Fibonacci Fibonacci#ILFnHy replica.py:487 - HANDLE __call__ OK 2193.3ms\n",
      "Running load test:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:04<00:07,  1.64it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:03,977 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 4452.3ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055321)\u001b[0m INFO 2022-08-11 20:47:03,965 Fibonacci Fibonacci#vyAavR replica.py:487 - HANDLE __call__ OK 1365.2ms\n",
      "Running load test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:04<00:06,  1.79it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:04,385 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 4859.6ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055332)\u001b[0m INFO 2022-08-11 20:47:04,427 Fibonacci Fibonacci#awPdXK replica.py:487 - HANDLE __call__ OK 1544.9ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055331)\u001b[0m INFO 2022-08-11 20:47:04,378 Fibonacci Fibonacci#ionSkK replica.py:487 - HANDLE __call__ OK 1314.4ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055326)\u001b[0m INFO 2022-08-11 20:47:04,841 Fibonacci Fibonacci#ILFnHy replica.py:487 - HANDLE __call__ OK 1615.8ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055320)\u001b[0m INFO 2022-08-11 20:47:05,045 Fibonacci Fibonacci#ygQSdT replica.py:487 - HANDLE __call__ OK 1977.5ms\n",
      "Running load test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:05<00:06,  1.43it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:05,472 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 5946.5ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055321)\u001b[0m INFO 2022-08-11 20:47:05,470 Fibonacci Fibonacci#vyAavR replica.py:487 - HANDLE __call__ OK 1504.3ms\n",
      "Running load test:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:06<00:05,  1.57it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:05,942 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6416.5ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055331)\u001b[0m INFO 2022-08-11 20:47:05,941 Fibonacci Fibonacci#ionSkK replica.py:487 - HANDLE __call__ OK 1562.7ms\n",
      "Running load test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:06<00:01,  3.74it/s]\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,000 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6479.5ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,000 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6475.4ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,001 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6475.4ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,066 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6541.7ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,067 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6542.2ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,068 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6541.7ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055332)\u001b[0m INFO 2022-08-11 20:47:05,998 Fibonacci Fibonacci#awPdXK replica.py:487 - HANDLE __call__ OK 1571.0ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055326)\u001b[0m INFO 2022-08-11 20:47:06,065 Fibonacci Fibonacci#ILFnHy replica.py:487 - HANDLE __call__ OK 1223.2ms\n",
      "Running load test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:06<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent 20 requests in 6.8648200035095215. 2.913 QPS average. 0.343s per request.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,372 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6852.0ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,373 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6847.9ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=2055271)\u001b[0m INFO 2022-08-11 20:47:06,373 http_proxy 172.18.0.35 http_proxy.py:320 - GET / 200 6848.0ms\n",
      "\u001b[2m\u001b[36m(ServeReplica:Fibonacci pid=2055320)\u001b[0m INFO 2022-08-11 20:47:06,371 Fibonacci Fibonacci#ygQSdT replica.py:487 - HANDLE __call__ OK 1325.7ms\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:47:33,315\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(df6fb3677751f87522a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:47:46,498\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(d3dc40ed82fed97922a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:47:50,601\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(950710ca0c0c8c8622a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:48:24,030\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(65ed897d627e09b422a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:48:31,984\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(29fbb5e18d8ab0e922a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:48:42,040\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(82ed9248781c16e622a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:49:12,350\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(2b999731ff5077d622a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:49:22,644\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(35884bdefa233e9e22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:49:33,483\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(17663f8e4cb85ce622a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:49:51,827\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(6b26312ed72d66db22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:50:13,457\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(75c9c5f1a959607422a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:50:17,706\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(8b12467451cd141022a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:50:44,799\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(0d58c0dcd7e6edf522a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:50:50,793\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(7d05b47c74f9338422a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:51:06,150\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(6b1b569294da23d222a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:51:34,587\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(77c6d4aa475c874522a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:51:40,541\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(2080d78ecea7f5ca22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:52:04,407\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(4bb6e54c555cff2122a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:52:16,881\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(cc41e389a52af9cd22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:52:21,439\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(7b75f93babac552722a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:52:56,765\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(e3192d7c57cb0bca22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:53:00,679\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(9fedc52a8461f6ee22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m 2022-08-11 20:53:08,510\tINFO (unknown file):0 -- Task failed with unretryable exception: TaskID(f45d73b213aedc6f22a4ad49b65d0cb1bc94108d15000000).\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 709, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 713, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 655, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"python/ray/_raylet.pyx\", line 2243, in ray._raylet.CoreWorker.run_async_func_in_event_loop\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return self.__get_result()\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise self._exception\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py\", line 498, in _resume_span\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/controller.py\", line 184, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     return await (self.long_poll_host.listen_for_change(keys_to_snapshot_ids))\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.7/site-packages/ray/serve/_private/long_poll.py\", line 249, in listen_for_change\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m     raise asyncio.TimeoutError(\"Polling request timed out.\")\n",
      "\u001b[2m\u001b[36m(ServeController pid=2055228)\u001b[0m concurrent.futures._base.TimeoutError: Polling request timed out.\n"
     ]
    }
   ],
   "source": [
    "# Scale up\n",
    "num_replicas = 5\n",
    "lazy_handle = Fibonacci.options(num_replicas=num_replicas).bind(name=\"BiggerFasterFibonacci\")\n",
    "serve.run(lazy_handle)\n",
    "\n",
    "# Rerun the load test\n",
    "qps_5 = await load_test('/Fibonacci', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty big improvement! We are just about hitting 3 QPS now. Let's calculate the improvements and make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11x improvement from scaling to 5 replicas\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "improvement = round(qps_5 / qps_1, 2)\n",
    "print(f\"{improvement}x improvement from scaling to {num_replicas} replicas\")\n",
    "\n",
    "# Plot the improvement using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.bar([\"1 replica\", f\"{num_replicas} replicas\"], [qps_1, qps_5])\n",
    "plt.xlabel(\"Number of replicas\")\n",
    "plt.ylabel(\"QPS served\")\n",
    "plt.title(\"QPS vs number of replicas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That's a significant QPS improvement. Thanks to Ray, Serve can scale to hundreds of replicas to handle high QPS applications for compute intensive tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down Ray Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.shutdown()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Here are some exercises to become more familiar with Ray Serve:\n",
    "\n",
    "1. Try different numbers of replicas. Is there a limit to how high the QPS can go? Why?\n",
    "2. What is the overhead of sending a request via HTTP vs using the handle directly? \n",
    "3. Do requests get sent to different replicas? (check the Ray Dashboard)\n",
    "4. Write your own Serve Deployment and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "* Try the tutorials below with Ray Serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Framework-Specific Tutorials\n",
    "\n",
    "Ray Serve seamlessly integrates with popular Python ML libraries. Below are tutorials with some of these frameworks to help get you started.\n",
    "\n",
    " * [PyTorch Tutorial](https://docs.ray.io/en/latest/serve/tutorials/pytorch.html#serve-pytorch-tutorial)\n",
    " * [Scikit-Learn Tutorial](https://docs.ray.io/en/latest/serve/tutorials/sklearn.html#serve-sklearn-tutorial)\n",
    " * [Keras and Tensorflow Tutorial](https://docs.ray.io/en/latest/serve/tutorials/tensorflow.html#serve-tensorflow-tutorial)\n",
    " * [Ray Serve MLflow Deployment Plugin](https://github.com/ray-project/mlflow-ray-serve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next\n",
    "We will learn how you can use Ray Serve integration with [MLflow](https://mlflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“– [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "âž¡ [Next notebook](./ex_02_ray_serve_fastapi.ipynb) <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "250a0c8ad49f9e0ab80d6ffa587b8bd67c2b62f7c5238d34c3fd259cc7d4f5bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
