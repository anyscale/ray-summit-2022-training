{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674c4a6d-9fbf-46e3-be82-7b41aff25503",
   "metadata": {},
   "source": [
    "# Ray Serve - Integration with Model Registry MLflow\n",
    "\n",
    "Â© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "This tutorial example shows how to deploy models saved in a model registry such as MLflow to Ray Serve, using the simple Ray Serve deployment APIs. \n",
    "\n",
    "### Learning Objective:\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    " * Integrate with model registeries like [MLflow](https://mlflow.org/)\n",
    " * Train a scikit-learn classification model\n",
    " * Use MLflow `autolog()` method to automatically log all metrics, parameters, artifacts, and the model\n",
    " * Create a deployment class and deploy the model for serving from MLflow model artifacts\n",
    " * Deploy and serve the model\n",
    " \n",
    "<img src=\"images/serve_mlflow.png\" height=\"50%\" width=\"100%\">\n",
    "\n",
    "You can peruse the saved models' metrics, parameters, and artifacts in MLflow ui.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f75277-2913-4c3b-af9f-dc2e02d7f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from ray import serve\n",
    "import mlflow\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd875b51-69c0-4974-9af5-8d48da48479d",
   "metadata": {},
   "source": [
    "Define a utility function:\n",
    " * create Iris data set\n",
    " * use a classifier\n",
    " * train and fit model\n",
    " * track all experiments using MLflow `autolog(...)` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3bc89-5565-40ea-8bc5-49d885ff5e7e",
   "metadata": {},
   "source": [
    "### Step 1 & 2: Train the scikit-learn model and log to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9214ce1f-77bb-4df1-b0b3-10affaa8f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_model():\n",
    "    # load Iris data\n",
    "    iris_data = load_iris()\n",
    "    data, target, target_names = (iris_data['data'],\n",
    "                                  iris_data['target'],\n",
    "                                  iris_data['target_names'])\n",
    "\n",
    "    # Instantiate a model\n",
    "    model = GradientBoostingClassifier()\n",
    "\n",
    "    # Training and validation split\n",
    "    np.random.shuffle(data), np.random.shuffle(target)\n",
    "    train_x, train_y = data[:100], target[:100]\n",
    "    val_x, val_y = data[100:], target[100:]\n",
    "\n",
    "    # Create labels list as file\n",
    "    LABEL_PATH = os.path.join(tempfile.gettempdir(), \"iris_labels.json\")\n",
    "    with open(LABEL_PATH, \"w\") as f:\n",
    "        json.dump(target_names.tolist(), f)\n",
    "\n",
    "    # Train the model and save our label list as an MLflow artifact\n",
    "    # mlflow.sklearn.autolog automatically logs all parameters and metrics during\n",
    "    # the training.\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run() as run:\n",
    "        model.fit(train_x, train_y)\n",
    "        # Log label list as a artifact\n",
    "        mlflow.log_artifact(LABEL_PATH, artifact_path=\"labels\")\n",
    "    return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a399116-0b3e-48d3-8edb-49f149db99ba",
   "metadata": {},
   "source": [
    "### Step 3: Create our Ray Serve deployment class and deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d342d2-e1f0-42fb-b158-dcf4c1b1beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(route_prefix=\"/regressor\")\n",
    "class BoostingModel:\n",
    "    def __init__(self, uri):\n",
    "        # Load the model and label artifact from the local\n",
    "        # Mlflow model registry as a PyFunc Model\n",
    "        self.model = mlflow.pyfunc.load_model(model_uri=uri)\n",
    "\n",
    "        # Download the artifact list of labels\n",
    "        local_dir = tempfile.mkdtemp()\n",
    "        client = MlflowClient()\n",
    "        local_path = f\"{client.download_artifacts(run_id, 'labels', local_dir)}/iris_labels.json\"\n",
    "        with open(local_path, \"r\") as f:\n",
    "            self.label_list = json.load(f)\n",
    "\n",
    "    async def __call__(self, starlette_request):\n",
    "        payload = await starlette_request.json()\n",
    "        print(f\"Worker: received Starlette request with data: {payload}\")\n",
    "\n",
    "        # Get the input vector from the payload\n",
    "        input_vector = [\n",
    "            payload[\"sepal length\"],\n",
    "            payload[\"sepal width\"],\n",
    "            payload[\"petal length\"],\n",
    "            payload[\"petal width\"],\n",
    "        ]\n",
    "\n",
    "        # Convert the input vector to a Pandas DataFrame for prediction since\n",
    "        # an MLflow PythonFunc model, model.predict(...), takes pandas DataFrame\n",
    "        prediction = self.model.predict(pd.DataFrame([input_vector]))[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        return {\"result\": human_name}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd57e5-14bd-4fce-8975-035f2817ac2c",
   "metadata": {},
   "source": [
    "Train and save the model artifacts in MLflow.\n",
    "Here our MLflow model registry is the local file directory `./mlruns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0e9e8c-1275-4d41-8c41-0217f1b2e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/21 14:27:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/anaconda3/envs/ray-summit-training/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/6d0ef9f4095446058ea82c7007a2c8ae/model\n"
     ]
    }
   ],
   "source": [
    "run_id = create_and_save_model()\n",
    "# Construct model uri to load the model from our model registry\n",
    "uri = f\"runs:/{run_id}/model\"\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86259553-b297-4dbf-93b1-cb8591c59190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:27:48,080\tINFO services.py:1470 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(ServeController pid=63301)\u001b[0m INFO 2022-06-21 14:27:52,269 controller 63301 checkpoint_path.py:17 - Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(ServeController pid=63301)\u001b[0m INFO 2022-06-21 14:27:52,377 controller 63301 http_state.py:112 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:kEcuWS:SERVE_PROXY_ACTOR-node:127.0.0.1-0' on node 'node:127.0.0.1-0' listening on '127.0.0.1:8000'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.client.ServeControllerClient at 0x7f8a912ca9a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the Ray Serve instance\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61ba02-55f6-4b41-b682-cf8cd795037e",
   "metadata": {},
   "source": [
    "### Step 4: Deploy and serve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c152d04d-3a2a-4279-bc37-e41ff5ec85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:/6d0ef9f4095446058ea82c7007a2c8ae/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController pid=63301)\u001b[0m INFO 2022-06-21 14:28:21,078 controller 63301 deployment_state.py:1175 - Stopping 1 replicas of deployment 'BoostingModel' with outdated versions.\n",
      "\u001b[2m\u001b[36m(ServeController pid=63301)\u001b[0m INFO 2022-06-21 14:28:23,261 controller 63301 deployment_state.py:1216 - Adding 1 replicas to deployment 'BoostingModel'.\n"
     ]
    }
   ],
   "source": [
    "# Deploy our model.\n",
    "print(uri)\n",
    "BoostingModel.deploy(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1529c81-cd2b-41f5-891f-ca77d2853e21",
   "metadata": {},
   "source": [
    "Send requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50cb75c5-18fa-4d56-9e02-77504eaa68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send in a request for labels types virginica, setosa, versicolor\n",
    "sample_request_inputs = [{\n",
    "    \"sepal length\": 6.3,\n",
    "    \"sepal width\": 3.3,\n",
    "    \"petal length\": 6.0,\n",
    "    \"petal width\": 2.5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42aedb74-aea4-485d-b983-5120fc3e10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"versicolor\"\n",
      "}\n",
      "\u001b[2m\u001b[36m(BoostingModel pid=63395)\u001b[0m Worker: received Starlette request with data: {'sepal length': 6.3, 'sepal width': 3.3, 'petal length': 6.0, 'petal width': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=63306)\u001b[0m INFO 2022-06-21 14:28:31,745 http_proxy 127.0.0.1 http_proxy.py:310 - GET /regressor 200 5.6ms\n",
      "\u001b[2m\u001b[36m(BoostingModel pid=63395)\u001b[0m INFO 2022-06-21 14:28:31,744 BoostingModel BoostingModel#nDZvax replica.py:478 - HANDLE __call__ OK 1.7ms\n"
     ]
    }
   ],
   "source": [
    "for input_request in sample_request_inputs:\n",
    "    response = requests.get(\"http://localhost:8000/regressor\",\n",
    "                            json=input_request)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165ad2a-6773-4730-be59-ecee886c06dc",
   "metadata": {},
   "source": [
    "### Launch the MLflow UI to see the metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8874e-7183-4674-bfe6-29442dee56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4caee-04e4-4d8c-a8d2-b2bfaf779aa8",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Increase the number of replicas to 2 or 3\n",
    "2. Add more samples to `sample_request_inputs`\n",
    "2. Send requests and observe which replica is serving them. You should see each being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7887d-7fc3-4888-8a9f-88124269918d",
   "metadata": {},
   "source": [
    "### Next\n",
    "\n",
    "We will learn how you can compose complex model using [ServerHandle APIs](https://docs.ray.io/en/latest/serve/ml-models.html#model-ensemble)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
