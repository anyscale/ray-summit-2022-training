{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214ce2a5-6b11-41d9-86f4-a2b4f0d1a6d9",
   "metadata": {},
   "source": [
    "### Model Composition ServerHandle APIs\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_04_inference_graphs.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_02_ray_serve_fastapi.ipynb) <br>\n",
    "\n",
    "<img src=\"images/PatternsMLProduction.png\" width=\"70%\" height=\"40%\">\n",
    "\n",
    "### Learning Objective:\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    " * compose models together as nodes of an inference graph. \n",
    " * scale each model independently as part of the graph by increasing replicas \n",
    " * use a single class to encompass all models as nodes into a deployment graph\n",
    "\n",
    "\n",
    "In this short tutorial we going to use HuggingFace Transformer ü§ó to accomplish three tasks:\n",
    " 1. Analyse the sentiment of a tweet: Positive or Negative\n",
    " 2. Translate it into French\n",
    " 3. Demonstrate the model composition deployment pattern using an inference graph\n",
    " \n",
    " <img src=\"images/sentiment_analysis.jpeg\" width=\"70%\" height=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d1ccb-6951-4e22-aafd-48c74c4635de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TranslationPipeline, TextClassificationPipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709b04e-cc7d-4869-8a9f-919d20a2b4cd",
   "metadata": {},
   "source": [
    "These are example üê¶ tweets, some made up, some extracted from a dog lover's twitter handle. In a real use case,\n",
    "these could come live from a Tweeter handle using [Twitter APIs](https://developer.twitter.com/en/docs/twitter-api/getting-started/getting-access-to-the-twitter-api). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b8bfd-1ee3-4d9c-bea4-e66924747ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS = [\"Tonight on my walk, I got mad because mom wouldn't let me play with this dog. We stared at each other...he never blinked!\",\n",
    "          \"Sometimes. when i am bored. i will stare at nothing. and try to convince the human. that there is a ghost\",\n",
    "          \"You little dog shit, you peed and pooed on my new carpet. Bad dog!\",\n",
    "          \"I would completely believe you. Dogs and little children - very innocent and open to seeing such things\",\n",
    "          \"You've got too much time on your paws. Go check on the skittle. under the, fridge\",\n",
    "          \"You sneaky little devil, I can't live without you!!!\",\n",
    "          \"It's true what they say about dogs: they are you BEST BUDDY, no matter what!\",\n",
    "          \"This dog is way dope, just can't enough of her\",\n",
    "          \"This dog is way cool, just can't enough of her\",\n",
    "          \"Is a dog really the best pet?\",\n",
    "          \"Cats are better than dogs\",\n",
    "          \"Totally dissastified with the dog. Worst dog ever\",\n",
    "          \"Briliant dog! Reads my moods like a book. Senses my moods and reacts. What a companinon!\"\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90287e-b3b9-498c-a2fc-fca7169b90fc",
   "metadata": {},
   "source": [
    "Utiliy function to fetch a tweet; these could very well be live tweets coming from Twitter API for a user or a #hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6e502-0e23-470d-84f3-fbfdf80f4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tweet_text(i):\n",
    "    text = TWEETS[i]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13f240-0412-4f14-943d-98a71d5d2b43",
   "metadata": {},
   "source": [
    "### Sentiment model deployment\n",
    "\n",
    "Our function deployment model to analyse the tweet using a pretrained transformer from HuggingFace ü§ó.\n",
    "Note we have number of `replicas=1` but to scale it, we can increase the number of replicas, as\n",
    "we have done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cf772-0fa6-4eaf-8288-b1cb5836f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(num_replicas=1)\n",
    "class SentimentTweet:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", model_max_length=128)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "        self.pipeline = TextClassificationPipeline(model=self.model, tokenizer=self.tokenizer, task=\"sentiment-analysis\")\n",
    "\n",
    "    def sentiment(self, text: str):\n",
    "        return (f\"label:{self.pipeline(text)[0]['label']}; score={self.pipeline(text)[0]['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a5f64-5c28-4af0-b266-4566e1f40c1a",
   "metadata": {},
   "source": [
    "### Translation model deployment\n",
    "\n",
    "Our function to translate a tweet from English --> French using a pretrained Transformer from HuggingFace ü§ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813a1c8-c577-4028-ad09-8b4dea439e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(num_replicas=2)\n",
    "class TranslateTweet:\n",
    "    def __init__(self):\n",
    "         self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", model_max_length=128)\n",
    "         self.model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "         self.use_gpu = 0 if torch.cuda.is_available() else -1\n",
    "         self.pipeline = TranslationPipeline(self.model, self.tokenizer, task=\"translation_en_to_fr\", device=self.use_gpu)\n",
    "\n",
    "    def translate(self, text: str):\n",
    "        return self.pipeline(text)[0]['translation_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9575b2a-11c3-40ea-8522-64ed27fdcbdf",
   "metadata": {},
   "source": [
    "### Use the Model Composition pattern\n",
    "\n",
    "<img src=\"images/tweet_composition.png\" width=\"60%\" height=\"25%\">\n",
    "\n",
    "A composed class is deployed with both sentiment analysis and translations models' ServeHandles initialized in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cec76c-3ef5-4741-914b-edb2c4fd2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(route_prefix=\"/composed\", num_replicas=2)\n",
    "class ComposedModel:\n",
    "    def __init__(self, translate, sentiment):\n",
    "        # fetch and initialize deployment handles\n",
    "        self.translate_model = translate\n",
    "        self.sentiment_model = sentiment\n",
    "\n",
    "    async def __call__(self, http_request):\n",
    "        data = await http_request.json()\n",
    "        sentiment_ref = await self.sentiment_model.sentiment.remote(data)\n",
    "        trans_text_ref = await self.translate_model.translate.remote(data)\n",
    "        sentiment_val = await sentiment_ref\n",
    "        trans_text = await trans_text_ref\n",
    "\n",
    "        return {'Sentiment': sentiment_val, 'Translated Text': trans_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26264457-b699-48ff-b5a8-f9a8d66c95f6",
   "metadata": {},
   "source": [
    "### Deploy our models \n",
    "\n",
    "Deploy our models. Our composed class is deployed with both sentiment analysis and translations models' `ClassNode` initialized in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39401d3-8fb0-410c-bb61-d25164fbeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_cls_node = TranslateTweet.bind()\n",
    "sentiment_cls_node = SentimentTweet.bind()\n",
    "compose_cls_node = ComposedModel.bind(translate_cls_node,sentiment_cls_node )\n",
    "\n",
    "serve.run(compose_cls_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea6006-d578-4eaa-9e95-6b2b6d4ff04a",
   "metadata": {},
   "source": [
    "### Send HTTP requests to our deployment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e72dd6-df3b-4236-bd78-d4b0b9bec98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TWEETS)):\n",
    "    tweet = fetch_tweet_text(i)\n",
    "    response = requests.post(\"http://127.0.0.1:8000/composed\", json=tweet)\n",
    "    print(f\"tweet request... : {tweet}\")\n",
    "    print(f\"tweet response:{response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d9b3f-e349-4af6-b9c1-e4ff0a2dab9e",
   "metadata": {},
   "source": [
    "Gracefully shutdown the Ray serve instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fcf2e-1afa-4900-bc3f-0fc8844d5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190d581-6a31-43f2-9083-94578042efdf",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Add more tweets to `TWEETS` with different sentiments.\n",
    "2. Check the score (and if you speak and read French, what you think of the translation?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4e209-4437-426e-a425-39b443df68a1",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. Instead of French, use a language transformer of your choice\n",
    "2. What about Neutral tweets? Try using [vaderSentiment](https://github.com/cjhutto/vaderSentiment)\n",
    "3. Solution for 2) is [here](https://github.com/anyscale/academy/blob/main/ray-serve/05-Ray-Serve-SentimentAnalysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476075b-d538-4ba4-84fa-02688b013a4d",
   "metadata": {},
   "source": [
    "### Next\n",
    "\n",
    "We'll further explore model composition using [Deploymant Graph APIs](https://docs.ray.io/en/latest/serve/deployment-graph.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d2797-a9ca-4f2f-bcd2-477667109fac",
   "metadata": {},
   "source": [
    "üìñ [Back to Table of Contents](./ex_00_tutorial_overview.ipynb)<br>\n",
    "‚û° [Next notebook](./ex_04_inference_graphs.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_02_ray_serve_fastapi.ipynb) <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "250a0c8ad49f9e0ab80d6ffa587b8bd67c2b62f7c5238d34c3fd259cc7d4f5bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
